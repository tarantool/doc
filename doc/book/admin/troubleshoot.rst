.. _admin-troubleshoot:
.. _admin-troubleshooting-guide:

================================================================================
Troubleshooting guide
================================================================================

.. _admin-troubleshoot-memory-issues:

--------------------------------------------------------------------------------
Problem: INSERT/UPDATE-requests result in ER_MEMORY_ISSUE error
--------------------------------------------------------------------------------

**Possible reasons**

* Lack of RAM (parameters ``arena_used_ratio`` and ``quota_used_ratio`` in
  :ref:`box.slab.info() <box_slab_info>` report are getting close to 100%).

  To check these parameters, say:

  .. code-block:: console

      $ # attaching to a Tarantool instance
      $ tarantoolctl enter <instance_name>
      $ # -- OR --
      $ tarantoolctl connect <URI>

  .. code-block:: tarantoolsession

      -- requesting arena_used_ratio value
      tarantool> box.slab.info().arena_used_ratio

      -- requesting quota_used_ratio value
      tarantool> box.slab.info().quota_used_ratio

**Solution**

Try either of the following measures:

* In Tarantool's :ref:`instance file <admin-instance_config>`, increase the
  value of :ref:`box.cfg{memtx_memory} <cfg_storage-memtx_memory>`
  (if memory resources are available).

  In versions of Tarantool before 1.10, the server needs to be restarted
  to change this parameter. The Tarantool
  server will be unavailable while restarting from .xlog files, unless
  you restart it using :ref:`hot standby <index-hot_standby>` mode.
  In the latter case, nearly 100% server availability is guaranteed.

* Clean up the database.

* Check the indicators of memory fragmentation:

  .. code-block:: tarantoolsession

      -- requesting quota_used_ratio value
      tarantool> box.slab.info().quota_used_ratio

      -- requesting items_used_ratio value
      tarantool> box.slab.info().items_used_ratio

  In case of heavy memory fragmentation (``quota_used_ratio`` is getting close
  to 100%, ``items_used_ratio`` is about 50%), we recommend restarting Tarantool
  in the :ref:`hot standby <index-hot_standby>` mode.

.. _admin-troubleshoot-cpu-load:

--------------------------------------------------------------------------------
Problem: Tarantool generates too heavy CPU load
--------------------------------------------------------------------------------

**Possible reasons**

The :ref:`transaction processor thread <atomic-threads_fibers_yields>` consumes
over 60% CPU.

**Solution**

Attach to the Tarantool instance with :ref:`tarantoolctl <tarantoolctl>` utility,
analyze the query statistics with :ref:`box.stat() <box_introspection-box_stat>`
and spot the CPU consumption leader. The following commands can help:

.. code-block:: console

    $ # attaching to a Tarantool instance
    $ tarantoolctl enter <instance_name>
    $ # -- OR --
    $ tarantoolctl connect <URI>

.. code-block:: tarantoolsession

    -- checking the RPS of calling stored procedures
    tarantool> box.stat().CALL.rps

The critical RPS value is 75 000, boiling down to 10 000 - 20 000 for a rich
Lua application (a Lua module of 200+ lines).

.. code-block:: tarantoolsession

    -- checking RPS per query type
    tarantool> box.stat().<query_type>.rps

The critical RPS value for SELECT/INSERT/UPDATE/DELETE requests is 100 000.

If the load is mostly generated by SELECT requests, we recommend adding a
:ref:`slave server <replication-bootstrap>` and let it process part of the
queries.

If the load is mostly generated by INSERT/UPDATE/DELETE requests, we recommend
:ref:`sharding the database <shard-module>`.

.. _admin-troubleshoot-query-timeout:

--------------------------------------------------------------------------------
Problem: Query processing times out
--------------------------------------------------------------------------------

**Possible reasons**

.. NOTE::

     All reasons that we discuss here can be identified by messages
     in Tarantool's log file, all starting with the words ``'Too long...'``.

1. Both fast and slow queries are processed within a single connection, so the
   readahead buffer is cluttered with slow queries.

   **Solution**

   Try either of the following measures:

   * Increase the readahead buffer size
     (:ref:`box.cfg{readahead} <cfg_networking-readahead>` parameter).

     This parameter can be changed on the fly, so you don't need to restart
     Tarantool. Attach to the Tarantool instance with
     :ref:`tarantoolctl <tarantoolctl>` utility and call ``box.cfg{}`` with a
     new ``readahead`` value:

     .. code-block:: console

         $ # attaching to a Tarantool instance
         $ tarantoolctl enter <instance_name>
         $ # -- OR --
         $ tarantoolctl connect <URI>

     .. code-block:: tarantoolsession

         -- changing the readahead value
         tarantool> box.cfg{readahead = 10 * 1024 * 1024}

     **Example:** Given 1000 RPS, 1 Кbyte of query size, and 10 seconds of
     maximal query processing time, the minimal readahead buffer size must be
     10 Mbytes.

   * On the business logic level, split fast and slow queries processing by
     different connections.

2. Slow disks.

   **Solution**

   Check disk performance (use `iostat <https://linux.die.net/man/1/iostat>`_,
   `iotop <https://linux.die.net/man/1/iotop>`_ or
   `strace <https://linux.die.net/man/1/strace>`_ utility to
   check ``iowait`` parameter) and try to put .xlog files and snapshot files on
   different physical disks (i.e. use different locations for
   :ref:`wal_dir <cfg_basic-wal_dir>` and :ref:`memtx_dir <cfg_basic-memtx_dir>`).

.. _admin-troubleshoot-negative-lag-idle:

--------------------------------------------------------------------------------
Problem: Replication "lag" and "idle" contain negative values
--------------------------------------------------------------------------------

This is about ``box.info.replication.(upstream.)lag`` and
``box.info.replication.(upstream.)idle`` values in
:ref:`box.info.replication <box_info_replication>` section.

**Possible reasons**

Operating system clock on the hosts is not synchronized, or the NTP server is
faulty.

**Solution**

Check NTP server settings.

If you found no problems with the NTP server, just do nothing then.
Lag calculation uses operating system clock from two different machines.
If they get out of sync, the remote master clock can get consistently behind
the local instance’s clock.

.. _admin-troubleshoot-idle-grows-no-logs:

--------------------------------------------------------------------------------
Problem: Replication "idle" keeps growing, but no related log messages appear
--------------------------------------------------------------------------------

This is about ``box.info.replication.(upstream.)idle`` value in
:ref:`box.info.replication <box_info_replication>` section.

**Possible reasons**

Some server was assigned different IP addresses, or some server was specified
twice in ``box.cfg{}``, so duplicate connections were established.

**Solution**

:ref:`Upgrade Tarantool 1.6 to 1.7 <admin-upgrades_instance>`, where this error
is fixed: in case of duplicate connections, replication is stopped and the
following message is added to the log:
``'Incorrect value for option ''replication_source'': duplicate connection with
the same replica UUID'``.

.. _admin-troubleshoot-mr-odd-replication-stats:

--------------------------------------------------------------------------------
Problem: Replication statistics differ on replicas within a replica set
--------------------------------------------------------------------------------

This is about a replica set that consists of one master and several replicas.
In a replica set of this type, values in
:ref:`box.info.replication <box_info_replication>` section, like
``box.info.replication.lsn``, come from the master and must be the same on all
replicas within the replica set. The problem is that they get different.

**Possible reasons**

Replication is broken.

**Solution**

:ref:`Restart replication <replication-recover>`.

.. _admin-troubleshoot-mm-replication-stopped:

--------------------------------------------------------------------------------
Problem: Master-master replication is stopped
--------------------------------------------------------------------------------

This is about :ref:`box.info.replication(.upstream).status <box_info_replication>`
= stopped.

**Possible reasons**

In a master-master replica set of two Tarantool instances, one of the masters
has tried to perform an action already performed by the other server,
for example re-insert a tuple with the same unique key. This would cause an
error message like
``'Duplicate key exists in unique index 'primary' in space <space_name>'``.

**Solution**

Restart replication with the following commands (at each master instance):

.. code-block:: console

    $ # attaching to a Tarantool instance
    $ tarantoolctl enter <instance_name>
    $ # -- OR --
    $ tarantoolctl connect <URI>

.. code-block:: tarantoolsession

    -- restarting replication
    tarantool> original_value = box.cfg.replication
    tarantool> box.cfg{replication={}}
    tarantool> box.cfg{replication=original_value}

We also recommend using text primary keys or setting up
:ref:`master-slave replication <replication-master_replica_bootstrap>`.

.. _admin-troubleshoot-slow-tarantool:

--------------------------------------------------------------------------------
Problem: Tarantool works much slower than before
--------------------------------------------------------------------------------

**Possible reasons**

Inefficient memory usage (RAM is cluttered with a huge amount of unused objects).

**Solution**

Call the Lua garbage collector with the
`collectgarbage('count') function <https://www.lua.org/manual/5.1/manual.html#pdf-collectgarbage>`_
and measure its execution time with the Tarantool functions
:ref:`clock.bench() <clock-bench>` or :ref:`clock.proc() <clock-proc>`.

Example of calculating memory usage statistics:

.. code-block:: console

    $ # attaching to a Tarantool instance
    $ tarantoolctl enter <instance_name>
    $ # -- OR --
    $ tarantoolctl connect <URI>

.. code-block:: tarantoolsession

    -- loading Tarantool's "clock" module with time-related routines
    tarantool> clock = require 'clock'
    -- starting the timer
    tarantool> b = clock.proc()
    -- launching garbage collection
    tarantool> c = collectgarbage('count')
    -- stopping the timer after garbage collection is completed
    tarantool> return c, clock.proc() - b

If the returned ``clock.proc()`` value is greater than 0.001, this may be an
indicator of inefficient memory usage (no active measures are required, but we
recommend to optimize your Tarantool application code).

If the value is greater than 0.01, your application definitely needs thorough
code analysis aimed at optimizing memory usage.
