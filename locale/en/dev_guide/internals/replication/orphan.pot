# SOME DESCRIPTIVE TITLE.
# Copyright (C) 
# This file is distributed under the same license as the Tarantool package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Tarantool 3.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-17 14:22+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../doc/dev_guide/internals/replication/orphan.rst:5
msgid "Orphan status"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:7
msgid "Starting with Tarantool version 1.9, there is a change to the procedure when an instance joins a replica set. During ``box.cfg()`` the instance tries to join all nodes listed in :ref:`box.cfg.replication <cfg_replication-replication>`. If the instance does not succeed with connecting to the required number of nodes (see :ref:`bootstrap_strategy <cfg_replication-bootstrap_strategy>`), it switches to the **orphan** status. While an instance is in orphan status, it is read-only."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:16
msgid "To \"join\" a master, a replica instance must \"connect\" to the master node and then \"sync\"."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:19
msgid "\"Connect\" means contact the master over the physical network and receive acknowledgment. If there is no acknowledgment after :ref:`box.replication_connect_timeout <cfg_replication-replication_connect_timeout>` seconds (usually 4 seconds), and retries fail, then the connect step fails."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:24
msgid "\"Sync\" means receive updates from the master in order to make a local database copy. Syncing is complete when the replica has received all the updates, or at least has received enough updates that the replica's lag (see :ref:`replication.upstream.lag <box_info_replication_upstream_lag>` in ``box.info()``) is less than or equal to the number of seconds specified in :ref:`box.cfg.replication_sync_lag <cfg_replication-replication_sync_lag>`. If ``replication_sync_lag`` is unset (nil) or set to TIMEOUT_INFINITY, then the replica skips the \"sync\" state and switches to \"follow\" immediately."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:36
msgid "In order to leave orphan mode, you need to sync with a sufficient number of instances (:ref:`bootstrap_strategy <cfg_replication-bootstrap_strategy>`). To do so, you may either:"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:40
msgid "Reset ``box.cfg.replication`` to exclude instances that cannot be reached or synced with."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:42
msgid "Set ``box.cfg.replication`` to ``\"\"`` (empty string)."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:44
msgid "The following situations are possible."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:48
msgid "**Situation 1: bootstrap**"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:50
msgid "Here ``box.cfg{}`` is being called for the first time. A replica is joining but no replica set exists yet."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:53
msgid "Set the status to 'orphan'."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:55
msgid "Try to connect to all nodes from ``box.cfg.replication``. The replica tries to connect for the :ref:`replication_connect_timeout <cfg_replication-replication_connect_timeout>` number of seconds and retries each :ref:`replication_timeout <cfg_replication-replication_timeout>` seconds if needed."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:61
msgid "Abort and throw an error if a replica is not connected to the majority of nodes in ``box.cfg.replication``."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:63
msgid "This instance might be elected as the replica set 'leader'. Criteria for electing a leader include vclock value (largest is best), and whether it is read-only or read-write (read-write is best unless there is no other choice). The leader is the master that other instances must join. The leader is the master that executes :doc:`box.once() </reference/reference_lua/box_once>` functions."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:70
msgid "If this instance is elected as the replica set leader, then perform an \"automatic bootstrap\":"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:74
msgid "Set status to 'running'."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:75
msgid "Return from ``box.cfg{}``."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:77
msgid "Otherwise this instance will be a replica joining an existing replica set, so:"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:80
msgid "Bootstrap from the leader. See examples in section :ref:`Bootstrapping a replica set <replication-bootstrap>`."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:82
msgid "In background, sync with all the other nodes in the replication set."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:84
msgid "**Situation 2: recovery**"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:86
msgid "Here ``box.cfg{}`` is not being called for the first time. It is being called again in order to perform recovery."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:89
msgid "Perform :ref:`recovery <internals-recovery_process>` from the last local snapshot and the WAL files."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:92
msgid "Try to establish connections to all other nodes for the :ref:`replication_connect_timeout <cfg_replication-replication_connect_timeout>` number of seconds. Once ``replication_connect_timeout`` is expired or all the connections are established, proceed to the \"sync\" state with all the established connections."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:96
msgid "If connected, sync with all connected nodes, until the difference is not more than :ref:`replication_sync_lag <cfg_replication-replication_sync_lag>` seconds."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:101
msgid "**Situation 3: configuration update**"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:103
msgid "Here ``box.cfg{}`` is not being called for the first time. It is being called again because some replication parameter or something in the replica set has changed."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:107
msgid "Try to connect to all nodes from ``box.cfg.replication``, within the time period specified in :ref:`replication_connect_timeout <cfg_replication-replication_connect_timeout>`."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:111
msgid "Try to sync with the connected nodes, within the time period specified in :ref:`replication_sync_timeout <cfg_replication-replication_sync_timeout>`."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:115
msgid "If earlier steps fail, change status to 'orphan'. (Attempts to sync will continue in the background and when/if they succeed then 'orphan' status will end.)"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:119
msgid "If earlier steps succeed, set status to 'running' (master) or 'follow' (replica)."
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:123
msgid "**Situation 4: rebootstrap**"
msgstr ""

#: ../../doc/dev_guide/internals/replication/orphan.rst:125
msgid "Here ``box.cfg{}`` is not being called. The replica connected successfully at some point in the past, and is now ready for an update from the master. But the master cannot provide an update. This can happen by accident, or more likely can happen because the replica is slow (its :ref:`lag <cfg_replication-replication_sync_lag>` is large), and the WAL (.xlog) files containing the updates have been deleted. This is not crippling. The replica can discard what it received earlier, and then ask for the master's latest snapshot (.snap) file contents. Since it is effectively going through the bootstrap process a second time, this is called \"rebootstrapping\". However, there has to be one difference from an ordinary bootstrap -- the replica's :ref:`replica id <replication-replica-id>` will remain the same. If it changed, then the master would think that the replica is a new addition to the cluster, and would maintain a record of an instance ID of a replica that has ceased to exist. Rebootstrapping was introduced in Tarantool version 1.10.2 and is completely automatic."
msgstr ""
