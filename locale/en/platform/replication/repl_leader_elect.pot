# SOME DESCRIPTIVE TITLE.
# Copyright (C) 
# This file is distributed under the same license as the Tarantool package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Tarantool 3.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-12-07 07:21+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../doc/concepts/replication/repl_leader_elect.rst:4
msgid "Automated leader election"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:6
msgid "Starting from version :doc:`2.6.1 </release/2.6.1>`, Tarantool has the built-in functionality managing automated *leader election* in a replica set. This functionality increases the fault tolerance of the systems built on the base of Tarantool and decreases dependency on external tools for replica set management."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:13
msgid "To learn how to configure and monitor automated leader elections, check :ref:`Managing leader elections <how-to-repl_leader_elect>`."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:16
msgid "The following topics are described below:"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:25
msgid "Leader election and synchronous replication"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:27
msgid "Leader election and synchronous replication are implemented in Tarantool as a modification of the `Raft <https://en.wikipedia.org/wiki/Raft_(computer_science)>`__ algorithm. Raft is an algorithm of synchronous replication and automatic leader election. Its complete description can be found in the `corresponding document <https://raft.github.io/raft.pdf>`_."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:33
msgid "In Tarantool, :ref:`synchronous replication <repl_sync>` and leader election are supported as two separate subsystems. So it is possible to get synchronous replication but use an alternative algorithm for leader election. And vice versa -- elect a leader in the cluster but don't use synchronous spaces at all. Synchronous replication has a separate :ref:`documentation section <repl_sync>`. Leader election is described below."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:44
msgid "The system behavior can be specified exactly according to the Raft algorithm. To do this:"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:46
msgid "Ensure that the user has only synchronous spaces."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:47
msgid "Set the :ref:`replication.synchro_quorum <configuration_reference_replication_synchro_quorum>` option to ``N / 2 + 1``."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:48
msgid "Set the :ref:`replication.synchro_timeout <configuration_reference_replication_synchro_timeout>` option to infinity."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:49
msgid "In the :ref:`replication.election_fencing_mode <configuration_reference_replication_election_fencing_mode>` option, select either the ``soft`` mode (the default) or the ``strict`` mode, which is more restrictive."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:55
msgid "Leader election process"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:57
msgid "Automated leader election in Tarantool helps guarantee that there is at most one leader at any given moment of time in a replica set. A *leader* is a writable node, and all other nodes are non-writable -- they accept read-only requests exclusively."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:62
msgid "When :ref:`the election is enabled <repl_leader_elect_config>`, the life cycle of a replica set is divided into so-called *terms*. Each term is described by a monotonically growing number. After the first boot, each node has its term equal to 1. When a node sees that it is not a leader and there is no leader available for some time in the replica set, it increases the term and starts a new leader election round."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:69
msgid "Leader election happens via votes. The node that started the election votes for itself and sends vote requests to other nodes. Upon receiving vote requests, a node votes for the first of them, and then cannot do anything in the same term but wait for a leader to be elected."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:74
msgid "The node that collected a quorum of votes defined by the :ref:`replication.synchro_quorum <configuration_reference_replication_synchro_quorum>` parameter becomes the leader and notifies other nodes about that. Also, a split vote can happen when no nodes received a quorum of votes. In this case, after a random timeout, each node increases its term and starts a new election round if no new vote request with a greater term arrives during this time. Eventually, a leader is elected."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:83
msgid "If any unfinalized synchronous transactions are left from the previous leader, the new leader finalizes them automatically."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:86
msgid "All the non-leader nodes are called *followers*. The nodes that start a new election round are called *candidates*. The elected leader sends heartbeats to the non-leader nodes to let them know it is alive."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:90
msgid "In case there are no heartbeats for the period of :ref:`replication.timeout <configuration_reference_replication_timeout>` * 4, a non-leader node starts a new election if the following conditions are met:"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:93
msgid "The node has a quorum of connections to other cluster members."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:94
msgid "None of these cluster members can see the leader node."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:98
msgid "A cluster member considers the leader node to be alive if the member received heartbeats from the leader at least once during the ``replication.timeout * 4``, and there are no replication errors (the connection is not broken due to timeout or due to an error)."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:102
msgid "Terms and votes are persisted by each instance to preserve certain Raft guarantees."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:104
msgid "During the election, the nodes prefer to vote for those ones that have the newest data. So as if an old leader managed to send something before its death to a quorum of replicas, that data wouldn't be lost."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:108
msgid "When election is enabled, there must be connections between each node pair so as it would be the full mesh topology. This is needed because election messages for voting and other internal things need a direct connection between the nodes."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:115
msgid "In the classic Raft algorithm, a leader doesn't track its connectivity to the rest of the cluster. Once the leader is elected, it considers itself in the leader position until receiving a new term from another cluster node. This can lead to a split situation if the other nodes elect a new leader upon losing the connectivity to the previous one."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:119
msgid "The issue is resolved in Tarantool version :doc:`2.10.0 </release/2.10.0>` by introducing the leader *fencing* mode. The mode can be switched by the :ref:`replication.election_fencing_mode <configuration_reference_replication_election_fencing_mode>` configuration parameter. When the fencing is set to ``soft`` or ``strict``, the leader resigns its leadership if it has less than :ref:`replication.synchro_quorum <configuration_reference_replication_synchro_quorum>` of alive connections to the cluster nodes. The resigning leader receives the status of a follower in the current election term and becomes read-only. Leader *fencing* can be turned off by setting the :ref:`replication.election_fencing_mode <configuration_reference_replication_election_fencing_mode>` configuration parameter to ``off``."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:126
msgid "In ``soft`` mode, a connection is considered dead if there are no responses for :ref:`4 * replication.timeout <configuration_reference_replication_timeout>` seconds both on the current leader and the followers."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:129
msgid "In ``strict`` mode, a connection is considered dead if there are no responses for :ref:`2 * replication.timeout <configuration_reference_replication_timeout>` seconds on the current leader and for :ref:`4 * replication.timeout <configuration_reference_replication_timeout>` seconds on the followers. This improves chances that there is only one leader at any time."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:134
msgid "Fencing applies to the instances that have the :ref:`replication.election_mode <configuration_reference_replication_election_mode>` set to \"candidate\" or \"manual\"."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:138
msgid "There can still be a situation when a replica set has two leaders working independently (so-called *split-brain*). It can happen, for example, if a user mistakenly lowered the :ref:`replication.synchro_quorum <configuration_reference_replication_synchro_quorum>` below ``N / 2 + 1``. In this situation, to preserve the data integrity, if an instance detects the split-brain anomaly in the incoming replication data, it breaks the connection with the instance sending the data and writes the ``ER_SPLIT_BRAIN`` error in the log."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:143
msgid "Eventually, there will be two sets of nodes with the diverged data, and any node from one set is disconnected from any node from the other set with the ``ER_SPLIT_BRAIN`` error."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:146
msgid "Once noticing the error, a user can choose any representative from each of the sets and inspect the data on them. To correlate the data, the user should remove it from the nodes of one set, and reconnect them to the nodes from the other set that have the correct data."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:150
msgid "Also, if election is enabled on the node, it doesn't replicate from any nodes except the newest leader. This is done to avoid the issue when a new leader is elected, but the old leader has somehow survived and tries to send more changes to the other nodes."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:155
msgid "Term numbers also work as a kind of filter. For example, if election is enabled on two nodes and ``node1`` has the term number less than ``node2``, then ``node2`` doesn't accept any transactions from ``node1``."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:163
msgid "Managing leader elections"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:168
msgid "Configuration"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:170
msgid "replication:\n"
"  election_mode: <string>\n"
"  election_fencing_mode: <string>\n"
"  election_timeout: <seconds>\n"
"  timeout: <seconds>\n"
"  synchro_quorum: <count>"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:180
msgid ":ref:`replication.election_mode <configuration_reference_replication_election_mode>` -- specifies the role of a node in the leader election process."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:182
msgid ":ref:`replication.election_fencing_mode <configuration_reference_replication_election_fencing_mode>` -- specifies the :ref:`leader fencing mode <repl_leader_elect_fencing>`."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:183
msgid ":ref:`replication.election_timeout <configuration_reference_replication_election_timeout>` -- specifies the timeout between election rounds if the previous round ended up with a split vote."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:185
msgid ":ref:`replication.timeout <configuration_reference_replication_timeout>` -- a time interval (in seconds) used by a master to send heartbeat requests to a replica when there are no updates to send to this replica."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:186
msgid ":ref:`replication.synchro_quorum <configuration_reference_replication_synchro_quorum>` -- a number of replicas that should confirm the receipt of a :ref:`synchronous <repl_sync>` transaction before it can finish its commit."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:188
msgid "It is important to know that being a leader is not the only requirement for a node to be writable. The leader should also satisfy the following requirements:"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:191
msgid "The :ref:`database.mode <configuration_reference_database_mode>` option is set to ``rw``."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:193
msgid "The leader shouldn't be in the orphan state."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:195
msgid "Nothing prevents you from setting the ``database.mode`` option to ``ro``, but the leader won't be writable then. The option doesn't affect the election process itself, so a read-only instance can still vote and become a leader."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:203
msgid "Monitoring"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:205
msgid "To monitor the current state of a node regarding the leader election, use the :doc:`box.info.election </reference/reference_lua/box_info/election>` function."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:207
msgid "**Example:**"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:209
msgid "tarantool> box.info.election\n"
"---\n"
"- state: follower\n"
"  vote: 0\n"
"  leader: 0\n"
"  term: 1\n"
"..."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:219
msgid "The Raft-based election implementation logs all its actions with the ``RAFT:`` prefix. The actions are new Raft message handling, node state changing, voting, and term bumping."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:226
msgid "Important notes"
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:228
msgid "Leader election doesn't work correctly if the election quorum is set to less or equal than ``<cluster size> / 2``. In that case, a split vote can lead to a state when two leaders are elected at once."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:232
msgid "For example, suppose there are five nodes. When the quorum is set to ``2``, ``node1`` and ``node2`` can both vote for ``node1``. ``node3`` and ``node4`` can both vote for ``node5``. In this case, ``node1`` and ``node5`` both win the election. When the quorum is set to the cluster majority, that is ``(<cluster size> / 2) + 1`` or greater, the split vote is impossible."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:238
msgid "That should be considered when adding new nodes. If the majority value is changing, it's better to update the quorum on all the existing nodes before adding a new one."
msgstr ""

#: ../../doc/concepts/replication/repl_leader_elect.rst:242
msgid "Also, the automated leader election doesn't bring many benefits in terms of data safety when used *without* :ref:`synchronous replication <repl_sync>`. If the replication is asynchronous and a new leader gets elected, the old leader is still active and considers itself the leader. In such case, nothing stops it from accepting requests from clients and making transactions. Non-synchronous transactions are successfully committed because they are not checked against the quorum of replicas. Synchronous transactions fail because they are not able to collect the quorum -- most of the replicas reject these old leader's transactions since it is not a leader anymore."
msgstr ""
