
msgid "Disaster recovery"
msgstr "Аварийное восстановление"

msgid ""
"The minimal fault-tolerant Tarantool configuration would be a "
":ref:`replication cluster<replication-topologies>` that includes a master "
"and a replica, or two masters."
msgstr ""
"Минимальная отказоустойчивая конфигурация Tarantool -- это "
":ref:`репликационный кластер <replication-topologies>`, содержащий мастер и "
"реплику или два мастера."

msgid ""
"The basic recommendation is to configure all Tarantool instances in a "
"cluster to create :ref:`snapshot files <index-box_persistence>` at a regular"
" basis."
msgstr ""
"Основная рекомендация -- настраивать все экземпляры Tarantool в кластере  "
"таким образом, чтобы они регулярно создавали :ref:`файлы-снимки <index-"
"box_persistence>`."

msgid "Here follow action plans for typical crash scenarios."
msgstr "Ниже дано несколько инструкций для типовых аварийных сценариев."

msgid "Master-replica"
msgstr "Мастер-реплика"

msgid "Configuration: One master and one replica."
msgstr "Конфигурация: один мастер и одна реплика."

msgid "Problem: The master has crashed."
msgstr "Проблема: мастер вышел из строя."

msgid "Your actions:"
msgstr "План действий:"

msgid ""
"Ensure the master is stopped for good. For example, log in to the master "
"machine and use ``systemctl stop tarantool@<instance_name>``."
msgstr ""
"Убедитесь, что мастер полностью остановлен. Например, подключитесь к мастеру"
" и используйте команду ``systemctl stop tarantool@<имя_экземпляра>``."

msgid ""
"Switch the replica to master mode by setting :ref:`box.cfg.read_only "
"<cfg_basic-read_only>` parameter to *false* and let the load be handled by "
"the replica (effective master)."
msgstr ""
"Переключите реплику в режим мастера, установив параметру "
":ref:`box.cfg.read_only <cfg_basic-read_only>` значение *false*. Теперь вся "
"нагрузка пойдет только на реплику (по сути ставшую мастером)."

msgid ""
"Set up a replacement for the crashed master on a spare host, with "
":ref:`replication <cfg_replication-replication>` parameter set to replica "
"(effective master), so it begins to catch up with the new master’s state. "
"The new instance should have :ref:`box.cfg.read_only <cfg_basic-read_only>` "
"parameter set to *true*."
msgstr ""
"Настройте на свободной машине замену вышедшему из строя мастеру, установив "
"параметру :ref:`replication <cfg_replication-replication>` в качестве "
"значения URI реплики (которая в данный момент выполняет роль мастера), чтобы"
" новая реплика начала синхронизироваться с текущим мастером. Значение "
"параметра :ref:`box.cfg.read_only <cfg_basic-read_only>` в новом экземпляре "
"должно быть установлено на *true*."

msgid ""
"You lose the few transactions in the master :ref:`write ahead log file "
"<index-box_persistence>`, which it may have not transferred to the replica "
"before crash. If you were able to salvage the master .xlog file, you may be "
"able to recover these. In order to do it:"
msgstr ""
"Все немногочисленные транзакции в :ref:`WAL-файле <index-box_persistence>` "
"мастера, которые он не успел передать реплике до выхода  из строя, будут "
"потеряны. Однако если удастся получить .xlog-файл мастера, их можно будет "
"восстановить. Для этого:"

msgid ""
"Find out the position of the crashed master, as reflected on the new master."
msgstr ""
"Узнайте позицию вышедшего из строя мастера -- эта информация доступна из "
"нового мастера."

msgid ""
"Find out instance UUID from the crashed master :ref:`xlog <internals-wal>`:"
msgstr ""
"Посмотрите UUID экземпляра в :ref:`xlog-файле <internals-wal>` вышедшего из "
"строя мастера:"

msgid ""
"$ head -5 *.xlog | grep Instance\n"
"Instance: ed607cad-8b6d-48d8-ba0b-dae371b79155"
msgstr ""
"$ head -5 *.xlog | grep Instance\n"
"Instance: ed607cad-8b6d-48d8-ba0b-dae371b79155"

msgid "On the new master, use the UUID to find the position:"
msgstr "Используйте этот UUID на новом мастере для поиска позиции:"

msgid ""
"tarantool> box.info.vclock[box.space._cluster.index.uuid:select{'ed607cad-8b6d-48d8-ba0b-dae371b79155'}[1][1]]\n"
"---\n"
"- 23425\n"
"<...>"
msgstr ""
"tarantool> box.info.vclock[box.space._cluster.index.uuid:select{'ed607cad-8b6d-48d8-ba0b-dae371b79155'}[1][1]]\n"
"---\n"
"- 23425\n"
"<...>"

msgid ""
"Play the records from the crashed .xlog to the new master, starting from the"
" new master position:"
msgstr ""
"Запишите транзакции из .xlog-файла вышедшего из строя мастера в новый "
"мастер, начиная с позиции нового мастера:"

msgid ""
"Issue this request locally at the new master's machine to find out instance "
"ID of the new master:"
msgstr ""
"Локально выполните эту команду на новом мастере, чтобы узнать его ID "
"экземпляра:"

msgid ""
"tarantool> box.space._cluster:select{}\n"
"---\n"
"- - [1, '88580b5c-4474-43ab-bd2b-2409a9af80d2']\n"
"..."
msgstr ""
"tarantool> box.space._cluster:select{}\n"
"---\n"
"- - [1, '88580b5c-4474-43ab-bd2b-2409a9af80d2']\n"
"..."

msgid "Play the records to the new master:"
msgstr "Запишите транзакции в новый мастер:"

msgid ""
"$ tarantoolctl <new_master_uri> <xlog_file> play --from 23425 --replica 1"
msgstr ""
"$ tarantoolctl <uri_нового_мастера> <xlog_файл> play --from 23425 --replica "
"1"

msgid "Master-master"
msgstr "Мастер-мастер"

msgid "Configuration: Two masters."
msgstr "Конфигурация: два мастера."

msgid "Problem: Master#1 has crashed."
msgstr "Проблема: мастер #1 вышел из строя."

msgid "Let the load be handled by master#2 (effective master) alone."
msgstr "Пусть вся нагрузка идет только на мастер #2 (действующий мастер)."

msgid ""
"2. Follow the same steps as in the :ref:`master-replica <admin-"
"disaster_recovery-master_replica>` recovery scenario to create a new master "
"and salvage lost data."
msgstr ""
"2. Создайте новый мастер и восстановите данные, проделав те же шаги, что и в"
" сценарии для конфигурации :ref:`мастер-реплика <admin-disaster_recovery-"
"master_replica>`."

msgid "Data loss"
msgstr "Потеря данных"

msgid "Configuration: Master-master or master-replica."
msgstr "Конфигурация: мастер-мастер или мастер-реплика."

msgid ""
"Problem: Data was deleted at one master and this data loss was propagated to"
" the other node (master or replica)."
msgstr ""
"Проблема: данные были удалены на одном мастере, а затем эти изменения "
"реплицировались на другом узле (мастере или реплике)."

msgid ""
"The following steps are applicable only to data in memtx storage engine. "
"Your actions:"
msgstr ""
"Эта инструкция применима только для данных, хранящихся на движке memtx. План"
" действий:"

msgid ""
"Put all nodes in :ref:`read-only mode <cfg_basic-read_only>` and disable "
"deletion of expired checkpoints with "
":doc:`/reference/reference_lua/box_backup/start`. This will prevent the "
"Tarantool garbage collector from removing files made with older checkpoints "
"until :doc:`/reference/reference_lua/box_backup/stop` is called."
msgstr ""
"Перевести все узлы в режим :ref:`read-only <cfg_basic-read_only>` и не "
"разрешать функции :doc:`/reference/reference_lua/box_backup/start` удалять "
"старые контрольные точки. Это не даст сборщику мусора в Tarantool удалять "
"файлы, созданные во время предыдущих контрольных точек, до тех пор пока не "
"будет вызвана функция :ref:`box.backup.stop() <reference_lua-box_backup-"
"backup_stop>`."

msgid ""
"Get the latest valid :ref:`.snap file <internals-snapshot>` and use "
"``tarantoolctl cat`` command to calculate at which lsn the data loss "
"occurred."
msgstr ""
"Возьмите последний корректный :ref:`.snap-файл <internals-snapshot>` и, "
"используя команду ``tarantoolctl cat``, выясните, на каком именно lsn "
"произошла потеря данных."

msgid ""
"Start a new instance (instance#1) and use ``tarantoolctl play`` command to "
"play to it the contents of .snap/.xlog files up to the calculated lsn."
msgstr ""
"Запустите новый экземпляр (экземпляр #1) и с помощью команды ``tarantoolctl "
"play`` скопируйте в него содержимое .snap/.xlog-файлов вплоть до "
"вычисленного lsn."

msgid "Bootstrap a new replica from the recovered master (instance#1)."
msgstr ""
"Настройте новую реплику с помощью восстановленного мастера (экземпляра #1)."
