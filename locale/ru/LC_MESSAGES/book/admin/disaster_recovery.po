
msgid "Disaster recovery"
msgstr "Аварийное восстановление"

msgid ""
"The minimal fault-tolerant Tarantool configuration would be a "
":ref:`replication cluster<replication-topologies>` that includes a master"
" and a replica, or two masters."
msgstr ""
"Минимальная отказоустойчивая конфигурация Tarantool'а -- это "
":ref:`репликационный кластер <replication-topologies>`, содержащий мастер"
" и реплику или два мастера."

msgid ""
"The basic recommendation is to configure all Tarantool instances in a "
"cluster to create :ref:`snapshot files <index-box_persistence>` at a "
"regular basis."
msgstr ""
"Основная рекомендация -- настраивать все экземпляры Tarantool'а в "
"кластере  таким образом, чтобы они регулярно создавали :ref:`файлы-снимки"
" <index-box_persistence>`."

msgid "Here follow action plans for typical crash scenarios."
msgstr "Ниже дано несколько инструкций для типовых аварийных сценариев."

msgid "Master-replica"
msgstr "Мастер-реплика"

msgid "Configuration: One master and one replica."
msgstr "Конфигурация: один мастер и одна реплика."

msgid "Problem: The master has crashed."
msgstr "Проблема: мастер вышел из строя."

msgid "Your actions:"
msgstr "План действий:"

msgid ""
"Ensure the master is stopped for good. For example, log in to the master "
"machine and use ``systemctl stop tarantool@<instance_name>``."
msgstr ""
"Убедитесь, что мастер полностью остановлен. Например, подключитесь к "
"мастеру и используйте команду ``systemctl stop "
"tarantool@<имя_экземпляра>``."

msgid ""
"Switch the replica to master mode by setting :ref:`box.cfg.read_only "
"<cfg_basic-read_only>` parameter to *false* and let the load be handled "
"by the replica (effective master)."
msgstr ""
"Переключите реплику в режим мастера, установив параметру "
":ref:`box.cfg.read_only <cfg_basic-read_only>` значение *false*. Теперь "
"вся нагрузка пойдет только на реплику (по сути ставшую мастером)."

msgid ""
"Set up a replacement for the crashed master on a spare host, with "
":ref:`replication <cfg_replication-replication>` parameter set to replica"
" (effective master), so it begins to catch up with the new master’s "
"state. The new instance should have :ref:`box.cfg.read_only <cfg_basic-"
"read_only>` parameter set to *true*."
msgstr ""
"Настройте на свободной машине замену вышедшему из строя мастеру, "
"установив параметру :ref:`replication <cfg_replication-replication>` в "
"качестве значения URI реплики (которая в данный момент выполняет роль "
"мастера), чтобы новая реплика начала синхронизироваться с текущим "
"мастером. Значение параметра :ref:`box.cfg.read_only <cfg_basic-"
"read_only>` в новом экземпляре должно быть установлено на *true*."

msgid ""
"You lose the few transactions in the master :ref:`write ahead log file "
"<index-box_persistence>`, which it may have not transferred to the "
"replica before crash. If you were able to salvage the master .xlog file, "
"you may be able to recover these. In order to do it:"
msgstr ""
"Все немногочисленные транзакции в :ref:`WAL-файле <index-"
"box_persistence>` мастера, которые он не успел передать реплике до выхода"
"  из строя, будут потеряны. Однако если удастся получить .xlog-файл "
"мастера, их можно будет восстановить. Для этого:"

msgid ""
"Find out the position of the crashed master, as reflected on the new "
"master."
msgstr ""
"Узнайте позицию вышедшего из строя мастера -- эта информация доступна из "
"нового мастера."

msgid ""
"Find out instance UUID from the crashed master :ref:`xlog <internals-"
"wal>`:"
msgstr ""
"Посмотрите UUID экземпляра в :ref:`xlog-файле <internals-wal>` вышедшего "
"из строя мастера:"

msgid ""
"$ head -5 *.xlog | grep Instance\n"
"Instance: ed607cad-8b6d-48d8-ba0b-dae371b79155"
msgstr ""
"$ head -5 *.xlog | grep Instance\n"
"Instance: ed607cad-8b6d-48d8-ba0b-dae371b79155"

msgid "On the new master, use the UUID to find the position:"
msgstr "Используйте этот UUID на новом мастере для поиска позиции:"

msgid ""
"tarantool> box.info.vclock[box.space._cluster.index.uuid:select"
"{'ed607cad-8b6d-48d8-ba0b-dae371b79155'}[1][1]]\n"
"---\n"
"- 23425\n"
"<...>"
msgstr ""
"tarantool> box.info.vclock[box.space._cluster.index.uuid:select"
"{'ed607cad-8b6d-48d8-ba0b-dae371b79155'}[1][1]]\n"
"---\n"
"- 23425\n"
"<...>"

msgid ""
"Play the records from the crashed .xlog to the new master, starting from "
"the new master position:"
msgstr ""
"Запишите транзакции из .xlog-файла вышедшего из строя мастера в новый "
"мастер, начиная с позиции нового мастера:"

msgid ""
"Issue this request locally at the new master's machine to find out "
"instance ID of the new master:"
msgstr ""
"Локально выполните эту команду на новом мастере, чтобы узнать его ID "
"экземпляра:"

msgid ""
"tarantool> box.space._cluster:select{}\n"
"---\n"
"- - [1, '88580b5c-4474-43ab-bd2b-2409a9af80d2']\n"
"..."
msgstr ""
"tarantool> box.space._cluster:select{}\n"
"---\n"
"- - [1, '88580b5c-4474-43ab-bd2b-2409a9af80d2']\n"
"..."

msgid "Play the records to the new master:"
msgstr "Запишите транзакции в новый мастер:"

msgid "$ tarantoolctl <new_master_uri> <xlog_file> play --from 23425 --replica 1"
msgstr ""
"$ tarantoolctl <uri_нового_мастера> <xlog_файл> play --from 23425 "
"--replica 1"

msgid "Master-master"
msgstr "Мастер-мастер"

msgid "Configuration: Two masters."
msgstr "Конфигурация: два мастера."

msgid "Problem: Master#1 has crashed."
msgstr "Проблема: мастер #1 вышел из строя."

msgid "Let the load be handled by master#2 (effective master) alone."
msgstr "Пусть вся нагрузка идет только на мастер #2 (действующий мастер)."

msgid ""
"2. Follow the same steps as in the :ref:`master-replica <admin-"
"disaster_recovery-master_replica>` recovery scenario to create a new "
"master and salvage lost data."
msgstr ""
"2. Создайте новый мастер и восстановите данные, проделав те же шаги, что "
"и в сценарии для конфигурации :ref:`мастер-реплика <admin-"
"disaster_recovery-master_replica>`."

msgid "Data loss"
msgstr "Потеря данных"

msgid "Configuration: Master-master or master-replica."
msgstr "Конфигурация: мастер-мастер или мастер-реплика."

msgid ""
"Problem: Data was deleted at one master and this data loss was propagated"
" to the other node (master or replica)."
msgstr ""
"Проблема: данные были удалены на одном мастере, а затем эти изменения "
"реплицировались на другом узле (мастере или реплике)."

msgid ""
"The following steps are applicable only to data in memtx storage engine. "
"Your actions:"
msgstr ""
"Эта инструкция применима только для данных, хранящихся на движке memtx. "
"План действий:"

msgid ""
"Put all nodes in :ref:`read-only mode <cfg_basic-read_only>` and disable "
"deletion of expired checkpoints with "
":doc:`/reference/reference_lua/box_backup/start`. This will prevent the "
"Tarantool garbage collector from removing files made with older "
"checkpoints until :doc:`/reference/reference_lua/box_backup/stop` is "
"called."
msgstr ""
"Перевести все узлы в режим :ref:`read-only <cfg_basic-read_only>` и не "
"разрешать функции :doc:`/reference/reference_lua/box_backup/start` "
"удалять старые контрольные точки. Это не даст сборщику мусора в Tarantool"
" удалять файлы, созданные во время предыдущих контрольных точек, до тех "
"пор пока не будет вызвана функция :ref:`box.backup.stop() <reference_lua-"
"box_backup-backup_stop>`."

msgid ""
"Get the latest valid :ref:`.snap file <internals-snapshot>` and use "
"``tarantoolctl cat`` command to calculate at which lsn the data loss "
"occurred."
msgstr ""
"Возьмите последний корректный :ref:`.snap-файл <internals-snapshot>` и, "
"используя команду ``tarantoolctl cat``, выясните, на каком именно lsn "
"произошла потеря данных."

msgid ""
"Start a new instance (instance#1) and use ``tarantoolctl play`` command "
"to play to it the contents of .snap/.xlog files up to the calculated lsn."
msgstr ""
"Запустите новый экземпляр (экземпляр #1) и с помощью команды "
"``tarantoolctl play`` скопируйте в него содержимое .snap/.xlog-файлов "
"вплоть до вычисленного lsn."

msgid "Bootstrap a new replica from the recovered master (instance#1)."
msgstr ""
"Настройте новую реплику с помощью восстановленного мастера (экземпляра "
"#1)."
