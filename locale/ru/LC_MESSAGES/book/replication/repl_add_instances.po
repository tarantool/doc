
msgid "Adding instances"
msgstr "Добавление экземпляров"

msgid "Adding a replica"
msgstr "Добавление реплики"

msgid ""
"To add a second **replica** instance to the **master-replica** set from our "
":ref:`bootstrapping example <replication-master_replica_bootstrap>`, we need"
" an analog of the instance file that we created for the first replica in "
"that set:"
msgstr ""
"Чтобы добавить вторую **реплику** в набор реплик с конфигурацией **мастер-"
"реплика** из нашего :ref:`примера настройки <replication-"
"master_replica_bootstrap>`, необходим аналог файла экземпляра, который мы "
"создали для первой реплики в этом наборе:"

msgid ""
"-- instance file for replica #2\n"
"box.cfg{\n"
"  listen = 3301,\n"
"  replication = {'replicator:password@192.168.0.101:3301',  -- master URI\n"
"                 'replicator:password@192.168.0.102:3301',  -- replica #1 URI\n"
"                 'replicator:password@192.168.0.103:3301'}, -- replica #2 URI\n"
"  read_only = true\n"
"}\n"
"box.once(\"schema\", function()\n"
"   box.schema.user.create('replicator', {password = 'password'})\n"
"   box.schema.user.grant('replicator', 'replication') -- grant replication role\n"
"   box.schema.space.create(\"test\")\n"
"   box.space.test:create_index(\"primary\")\n"
"   print('box.once executed on replica #2')\n"
"end)"
msgstr ""
"-- файл экземпляра для реплики №2\n"
"box.cfg{\n"
"  listen = 3301,\n"
"  replication = {'replicator:password@192.168.0.101:3301',  -- URI мастера\n"
"                 'replicator:password@192.168.0.102:3301',  -- URI реплики №1\n"
"                 'replicator:password@192.168.0.103:3301'}, -- URI реплики №2\n"
"  read_only = true\n"
"}\n"
"box.once(\"schema\", function()\n"
"   box.schema.user.create('replicator', {password = 'password'})\n"
"   box.schema.user.grant('replicator', 'replication') -- предоставить роль для репликации\n"
"   box.schema.space.create(\"test\")\n"
"   box.space.test:create_index(\"primary\")\n"
"   print('box.once executed on replica #2')\n"
"end)"

msgid ""
"Here we add the URI of replica #2 to the :ref:`replication <cfg_replication-"
"replication>` parameter, so now it contains three URIs."
msgstr ""
"Здесь мы добавляем URI реплики №2 в параметр :ref:`replication "
"<cfg_replication-replication>`, так что теперь он содержит три URI."

msgid ""
"After we launch the new replica instance, it gets connected to the master "
"instance and retrieves the master's write-ahead-log and snapshot files:"
msgstr ""
"После запуска новая реплика подключается к мастер-серверу и получает от него"
" журнал упреждающей записи и файлы снимков:"

msgid ""
"$ # launching replica #2\n"
"$ tarantool replica2.lua\n"
"2017-06-14 14:54:33.927 [46945] main/101/replica2.lua C> version 1.7.4-52-g980d30092\n"
"2017-06-14 14:54:33.927 [46945] main/101/replica2.lua C> log level 5\n"
"2017-06-14 14:54:33.928 [46945] main/101/replica2.lua I> mapping 268435456 bytes for tuple arena...\n"
"2017-06-14 14:54:33.930 [46945] main/104/applier/replicator@192.168.0.10 I> remote master is 1.7.4 at 192.168.0.101:3301\n"
"2017-06-14 14:54:33.930 [46945] main/104/applier/replicator@192.168.0.10 I> authenticated\n"
"2017-06-14 14:54:33.930 [46945] main/101/replica2.lua I> bootstrapping replica from 192.168.0.101:3301\n"
"2017-06-14 14:54:33.933 [46945] main/104/applier/replicator@192.168.0.10 I> initial data received\n"
"2017-06-14 14:54:33.933 [46945] main/104/applier/replicator@192.168.0.10 I> final data received\n"
"2017-06-14 14:54:33.934 [46945] snapshot/101/main I> saving snapshot `/var/lib/tarantool/replica2/00000000000000000010.snap.inprogress'\n"
"2017-06-14 14:54:33.934 [46945] snapshot/101/main I> done\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> vinyl checkpoint done\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> ready to accept requests\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> set 'read_only' configuration option to true\n"
"2017-06-14 14:54:33.936 [46945] main C> entering the event loop"
msgstr ""
"$ # запуск реплики №2\n"
"$ tarantool replica2.lua\n"
"2017-06-14 14:54:33.927 [46945] main/101/replica2.lua C> version 1.7.4-52-g980d30092\n"
"2017-06-14 14:54:33.927 [46945] main/101/replica2.lua C> log level 5\n"
"2017-06-14 14:54:33.928 [46945] main/101/replica2.lua I> mapping 268435456 bytes for tuple arena...\n"
"2017-06-14 14:54:33.930 [46945] main/104/applier/replicator@192.168.0.10 I> remote master is 1.7.4 at 192.168.0.101:3301\n"
"2017-06-14 14:54:33.930 [46945] main/104/applier/replicator@192.168.0.10 I> authenticated\n"
"2017-06-14 14:54:33.930 [46945] main/101/replica2.lua I> bootstrapping replica from 192.168.0.101:3301\n"
"2017-06-14 14:54:33.933 [46945] main/104/applier/replicator@192.168.0.10 I> initial data received\n"
"2017-06-14 14:54:33.933 [46945] main/104/applier/replicator@192.168.0.10 I> final data received\n"
"2017-06-14 14:54:33.934 [46945] snapshot/101/main I> saving snapshot `/var/lib/tarantool/replica2/00000000000000000010.snap.inprogress'\n"
"2017-06-14 14:54:33.934 [46945] snapshot/101/main I> done\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> vinyl checkpoint done\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> ready to accept requests\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> set 'read_only' configuration option to true\n"
"2017-06-14 14:54:33.936 [46945] main C> entering the event loop"

msgid ""
"Since we are adding a read-only instance, there is no need to dynamically "
"update the ``replication`` parameter on the other running instances. This "
"update would be required if we :ref:`added a master instance <replication-"
"add_master>`."
msgstr ""
"Поскольку мы добавляем экземпляр только для чтения (read-only), нет "
"необходимости в динамическом обновлении параметра ``replication`` на других "
"работающих экземплярах. Такое обновление необходимо, если бы мы "
":ref:`добавляли мастера <replication-add_master>`."

msgid ""
"However, we recommend specifying the URI of replica #3 in all instance files"
" of the replica set. This will keep all the files consistent with each other"
" and with the current replication topology, and so will help to avoid "
"configuration errors in case of further configuration updates and replica "
"set restart."
msgstr ""
"Тем не менее, рекомендуем указать URI реплики №3 во всех файлах экземпляра в"
" наборе реплик. Это поможет сохранить единообразие файлов и согласовать их с"
" текущей топологией репликации, а также не допустить ошибок конфигурации в "
"случае последующего обновления конфигурации и перезапуска набора реплик."

msgid "Adding a master"
msgstr "Добавление мастера"

msgid ""
"To add a third master instance to the **master-master** set from our "
":ref:`bootstrapping example <replication-master_master_bootstrap>`, we need "
"an analog of the instance files that we created to bootstrap the other "
"master instances in that set:"
msgstr ""
"Чтобы добавить третьего мастера в набор реплик с конфигурацией **мастер-"
"мастер** из нашего :ref:`примера настройки <replication-"
"master_master_bootstrap>`, необходим аналог файлов экземпляров, которые мы "
"создали для настройки других мастеров в этом наборе:"

msgid ""
"-- instance file for master #3\n"
"box.cfg{\n"
"  listen      = 3301,\n"
"  replication = {'replicator:password@192.168.0.101:3301',  -- master#1 URI\n"
"                 'replicator:password@192.168.0.102:3301',  -- master#2 URI\n"
"                 'replicator:password@192.168.0.103:3301'}, -- master#3 URI\n"
"  read_only   = true, -- temporarily read-only\n"
"}\n"
"box.once(\"schema\", function()\n"
"   box.schema.user.create('replicator', {password = 'password'})\n"
"   box.schema.user.grant('replicator', 'replication') -- grant replication role\n"
"   box.schema.space.create(\"test\")\n"
"   box.space.test:create_index(\"primary\")\n"
"end)"
msgstr ""
"-- файл экземпляра для мастера №3\n"
"box.cfg{\n"
"  listen      = 3301,\n"
"  replication = {'replicator:password@192.168.0.101:3301',  -- URI мастера №1\n"
"                 'replicator:password@192.168.0.102:3301',  -- URI мастера №2\n"
"                 'replicator:password@192.168.0.103:3301'}, -- URI мастера №3\n"
"  read_only   = true, -- временно только для чтения\n"
"}\n"
"box.once(\"schema\", function()\n"
"   box.schema.user.create('replicator', {password = 'password'})\n"
"   box.schema.user.grant('replicator', 'replication') -- выдача роли для репликации\n"
"   box.schema.space.create(\"test\")\n"
"   box.space.test:create_index(\"primary\")\n"
"end)"

msgid "Here we make the following changes:"
msgstr "Здесь мы вносим следующие изменения:"

msgid ""
"Add the URI of master #3 to the :ref:`replication <cfg_replication-"
"replication>` parameter."
msgstr ""
"Добавить URI мастера №3 в параметр :ref:`replication <cfg_replication-"
"replication>`."

msgid ""
"Temporarily specify :ref:`read_only=true <cfg_basic-read_only>` to disable "
"data-change operations on the instance. After launch, master #3 will act as "
"a replica until it retrieves all data from the other masters in the replica "
"set."
msgstr ""
"Временно укажите :ref:`read_only=true <cfg_basic-read_only>`, чтобы "
"отключить операции по изменению данных на этом экземпляре. После запуска "
"мастер №3 будет работать в качестве реплики, пока не получит все данные от "
"других мастеров в наборе реплик."

msgid ""
"After we launch master #3, it gets connected to the other master instances "
"and retrieves their write-ahead-log and snapshot files:"
msgstr ""
"После запуска мастер №3 подключается к другим мастер-экземплярам и получает "
"от них файлы журнала упреждающей записи и файлы снимков:"

msgid ""
"$ # launching master #3\n"
"$ tarantool master3.lua\n"
"2017-06-14 17:10:00.556 [47121] main/101/master3.lua C> version 1.7.4-52-g980d30092\n"
"2017-06-14 17:10:00.557 [47121] main/101/master3.lua C> log level 5\n"
"2017-06-14 17:10:00.557 [47121] main/101/master3.lua I> mapping 268435456 bytes for tuple arena...\n"
"2017-06-14 17:10:00.559 [47121] iproto/101/main I> binary: bound to [::]:3301\n"
"2017-06-14 17:10:00.559 [47121] main/104/applier/replicator@192.168.0.10 I> remote master is 1.7.4 at 192.168.0.101:3301\n"
"2017-06-14 17:10:00.559 [47121] main/105/applier/replicator@192.168.0.10 I> remote master is 1.7.4 at 192.168.0.102:3301\n"
"2017-06-14 17:10:00.559 [47121] main/106/applier/replicator@192.168.0.10 I> remote master is 1.7.4 at 192.168.0.103:3301\n"
"2017-06-14 17:10:00.559 [47121] main/105/applier/replicator@192.168.0.10 I> authenticated\n"
"2017-06-14 17:10:00.559 [47121] main/101/master3.lua I> bootstrapping replica from 192.168.0.102:3301\n"
"2017-06-14 17:10:00.562 [47121] main/105/applier/replicator@192.168.0.10 I> initial data received\n"
"2017-06-14 17:10:00.562 [47121] main/105/applier/replicator@192.168.0.10 I> final data received\n"
"2017-06-14 17:10:00.562 [47121] snapshot/101/main I> saving snapshot `/Users/e.shebunyaeva/work/tarantool-test-repl/master3_dir/00000000000000000009.snap.inprogress'\n"
"2017-06-14 17:10:00.562 [47121] snapshot/101/main I> done\n"
"2017-06-14 17:10:00.564 [47121] main/101/master3.lua I> vinyl checkpoint done\n"
"2017-06-14 17:10:00.564 [47121] main/101/master3.lua I> ready to accept requests\n"
"2017-06-14 17:10:00.565 [47121] main/101/master3.lua I> set 'read_only' configuration option to true\n"
"2017-06-14 17:10:00.565 [47121] main C> entering the event loop\n"
"2017-06-14 17:10:00.565 [47121] main/104/applier/replicator@192.168.0.10 I> authenticated"
msgstr ""
"$ # запуск мастера №3\n"
"$ tarantool master3.lua\n"
"2017-06-14 17:10:00.556 [47121] main/101/master3.lua C> version 1.7.4-52-g980d30092\n"
"2017-06-14 17:10:00.557 [47121] main/101/master3.lua C> log level 5\n"
"2017-06-14 17:10:00.557 [47121] main/101/master3.lua I> mapping 268435456 bytes for tuple arena...\n"
"2017-06-14 17:10:00.559 [47121] iproto/101/main I> binary: bound to [::]:3301\n"
"2017-06-14 17:10:00.559 [47121] main/104/applier/replicator@192.168.0.10 I> remote master is 1.7.4 at 192.168.0.101:3301\n"
"2017-06-14 17:10:00.559 [47121] main/105/applier/replicator@192.168.0.10 I> remote master is 1.7.4 at 192.168.0.102:3301\n"
"2017-06-14 17:10:00.559 [47121] main/106/applier/replicator@192.168.0.10 I> remote master is 1.7.4 at 192.168.0.103:3301\n"
"2017-06-14 17:10:00.559 [47121] main/105/applier/replicator@192.168.0.10 I> authenticated\n"
"2017-06-14 17:10:00.559 [47121] main/101/master3.lua I> bootstrapping replica from 192.168.0.102:3301\n"
"2017-06-14 17:10:00.562 [47121] main/105/applier/replicator@192.168.0.10 I> initial data received\n"
"2017-06-14 17:10:00.562 [47121] main/105/applier/replicator@192.168.0.10 I> final data received\n"
"2017-06-14 17:10:00.562 [47121] snapshot/101/main I> saving snapshot `/Users/e.shebunyaeva/work/tarantool-test-repl/master3_dir/00000000000000000009.snap.inprogress'\n"
"2017-06-14 17:10:00.562 [47121] snapshot/101/main I> done\n"
"2017-06-14 17:10:00.564 [47121] main/101/master3.lua I> vinyl checkpoint done\n"
"2017-06-14 17:10:00.564 [47121] main/101/master3.lua I> ready to accept requests\n"
"2017-06-14 17:10:00.565 [47121] main/101/master3.lua I> set 'read_only' configuration option to true\n"
"2017-06-14 17:10:00.565 [47121] main C> entering the event loop\n"
"2017-06-14 17:10:00.565 [47121] main/104/applier/replicator@192.168.0.10 I> authenticated"

msgid ""
"Next, we add the URI of master #3 to the ``replication`` parameter on the "
"existing two masters. Replication-related parameters are dynamic, so we only"
" need to make a ``box.cfg{}`` request on each of the running instances:"
msgstr ""
"Затем добавляем URI мастера №3 в параметр ``replication`` на существующих "
"мастерах. В конфигурации репликации используются динамические параметры, "
"поэтому необходимо только выполнить запрос ``box.cfg{}`` на каждом "
"работающем экземпляре:"

msgid ""
"# adding master #3 URI to replication sources\n"
"tarantool> box.cfg{replication =\n"
"         > {'replicator:password@192.168.0.101:3301',\n"
"         > 'replicator:password@192.168.0.102:3301',\n"
"         > 'replicator:password@192.168.0.103:3301'}}\n"
"---\n"
"..."
msgstr ""
"# добавление URI мастера №3 в источники репликации\n"
"tarantool> box.cfg{replication =\n"
"         > {'replicator:password@192.168.0.101:3301',\n"
"         > 'replicator:password@192.168.0.102:3301',\n"
"         > 'replicator:password@192.168.0.103:3301'}}\n"
"---\n"
"..."

msgid ""
"When master #3 catches up with the other masters' state, we can disable "
"read-only mode for this instance:"
msgstr ""
"Когда мастер №3 получает все необходимые изменения от других мастеров, можно"
" отключить режим только для чтения:"

msgid ""
"# making master #3 a real master\n"
"tarantool> box.cfg{read_only=false}\n"
"---\n"
"..."
msgstr ""
"# назначение мастера №3 настоящим мастером\n"
"tarantool> box.cfg{read_only=false}\n"
"---\n"
"..."

msgid ""
"We also recommend to specify master #3 URI in all instance files in order to"
" keep all the files consistent with each other and with the current "
"replication topology."
msgstr ""
"Также рекомендуется указать URI мастера №3 во всех файлах экземпляра, чтобы "
"сохранить единообразие файлов и согласовать их с текущей топологией "
"репликации."

msgid "Orphan status"
msgstr "Статус orphan (одиночный)"

msgid ""
"Starting with Tarantool version 1.9, there is a change to the procedure when"
" an instance joins a replica set. During ``box.cfg()`` the instance will try"
" to join all masters listed in :ref:`box.cfg.replication <cfg_replication-"
"replication>`. If the instance does not succeed with at least the number of "
"masters specified in :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`, then it will switch to **orphan status**. "
"While an instance is in orphan status, it is read-only."
msgstr ""
"Начиная с версии Tarantool 1.9, процедура подключения реплики к набору "
"реплик изменяется. Во время ``box.cfg()`` экземпляр попытается подключиться "
"ко всем мастерам, указанным в :ref:`box.cfg.replication <cfg_replication-"
"replication>`. Если не было успешно выполнено подключение к количеству "
"мастеров, указанному в :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`, экземпляр переходит в **статус orphan** "
"(одиночный). Когда экземпляр находится в статусе orphan, он доступен только "
"для чтения."

msgid ""
"To \"join\" a master, a replica instance must \"connect\" to the master node"
" and then \"sync\"."
msgstr ""
"Чтобы \"подключиться\" к мастеру, реплика должна \"установить соединение\" с"
" узлом мастера, а затем \"выполнить синхронизацию\"."

msgid ""
"\"Connect\" means contact the master over the physical network and receive "
"acknowledgment. If there is no acknowledgment after "
":ref:`box.replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>` seconds (usually 4 seconds), and retries fail,"
" then the connect step fails."
msgstr ""
"\"Установка соединения\" означает контакт с мастером по физической сети и "
"получение подтверждения. Если нет подтверждения соединения через "
":ref:`box.replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>` секунд (обычно 4 секунды), и повторные попытки"
" подключения не сработали, то соединение не установлено."

msgid ""
"\"Sync\" means receive updates from the master in order to make a local "
"database copy. Syncing is complete when the replica has received all the "
"updates, or at least has received enough updates that the replica's lag (see"
" :ref:`replication.upstream.lag <box_info_replication_upstream_lag>` in "
"``box.info()``) is less than or equal to the number of seconds specified in "
":ref:`box.cfg.replication_sync_lag <cfg_replication-replication_sync_lag>`. "
"If ``replication_sync_lag`` is unset (nil) or set to TIMEOUT_INFINITY, then "
"the replica skips the \"sync\" state and switches to \"follow\" immediately."
msgstr ""
"\"Синхронизация\" означает получение обновлений от мастера для создания "
"локальной копии базы данных. Синхронизация завершена, когда реплика получила"
" все обновления или хотя бы получила достаточное количество обновлений, "
"чтобы отставание реплики (см. :ref:`replication.upstream.lag "
"<box_info_replication_upstream_lag>` в ``box.info()``) было меньше или равно"
" количеству секунд, указанному в :ref:`box.cfg.replication_sync_lag "
"<cfg_replication-replication_sync_lag>`. Если значение "
"``replication_sync_lag`` не задано (nil) или указано как "
"\"TIMEOUT_INFINITY\", то реплика пропускает шаг \"синхронизация\" и сразу же"
" переходит на \"отслеживание\"."

msgid ""
"In order to leave orphan mode you need to sync with a sufficient number "
"(:ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`) of instances. To do so, you may either:"
msgstr ""
"Чтобы вывести узел из одиночного статуса, нужно синхронизировать его с "
"достаточным (т.е. равным :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`) количеством других узлов. Этого можно "
"добиться, выполнив любое из следующих действий:"

msgid ""
"Set :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>` to a lower value."
msgstr ""
"Уменьшить значение :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`."

msgid ""
"Reset ``box.cfg.replication`` to exclude instances that cannot be reached or"
" synced with."
msgstr ""
"Убрать из списка ``box.cfg.replication`` недоступные и прочие узлы, с "
"которыми нельзя синхронизироваться."

msgid "Set ``box.cfg.replication`` to ``\"\"`` (empty string)."
msgstr ""
"Вообще задать ``\"\"`` (пустую строку) в качестве значения "
"``box.cfg.replication``."

msgid "The following situations are possible."
msgstr "Возможны следующие ситуации."

msgid "**Situation 1: bootstrap**"
msgstr "**Ситуация 1: настройка**"

msgid ""
"Here ``box.cfg{}`` is being called for the first time. A replica is joining "
"but no replica set exists yet."
msgstr ""
"Здесь впервые происходит вызов ``box.cfg{}``. Реплика подключается, но "
"набора реплик пока нет."

msgid "Set status to 'orphan'."
msgstr "Установка статуса 'orphan' (одиночный)."

msgid ""
"Try to connect to all nodes from ``box.cfg.replication``, or to the number "
"of nodes required by :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`. Retrying up to 3 times in 30 seconds is "
"possible because this is bootstrap, :ref:`replication_connect_timeout "
"<cfg_replication-replication_connect_timeout>` is overridden."
msgstr ""
"Попытка установить соединение со всеми узлами из ``box.cfg.replication`` или"
" с количеством узлов, указанным в параметре :ref:`replication_connect_quorum"
" <cfg_replication-replication_connect_quorum>`. Допускаются три повторные "
"попытки за 30 секунд, поскольку идет стадия настройки, параметр "
":ref:`replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>` не учитывается."

msgid ""
"Abort and throw an error if not connected to all nodes in "
"``box.cfg.replication`` or :ref:`replication_connect_quorum "
"<cfg_replication-replication_connect_quorum>`."
msgstr ""
"Прекращение работы и выдача ошибки в случае отсутствия соединения со всеми "
"узлами в ``box.cfg.replication`` или :ref:`replication_connect_quorum "
"<cfg_replication-replication_connect_quorum>`."

msgid ""
"This instance might be elected as the replica set 'leader'. Criteria for "
"electing a leader include vclock value (largest is best), and whether it is "
"read-only or read-write (read-write is best unless there is no other "
"choice). The leader is the master that other instances must join. The leader"
" is the master that executes :doc:`box.once() "
"</reference/reference_lua/box_once>` functions."
msgstr ""
"Экземпляр может быть выбран в качестве лидера 'leader' в наборе реплик. "
"Критерии выбора лидера включают в себя значение vclock (чем больше, тем "
"лучше), а также доступность только для чтения или для чтения и записи (лучше"
" всего для чтения и записи, кроме случаев, когда других вариантов нет). "
"Лидер является мастером, к которому должны подключиться другие экземпляры. "
"Лидер является мастером, который выполняет функции :doc:`box.once() "
"</reference/reference_lua/box_once>`."

msgid ""
"If this instance is elected as the replica set leader, then perform an "
"\"automatic bootstrap\":"
msgstr ""
"Если данный экземпляр выбран лидером набора реплик, выполняется "
"\"самонастройка\":"

msgid "Set status to 'running'."
msgstr "Установка статуса 'running' (запущен)."

msgid "Return from ``box.cfg{}``."
msgstr "Возврат из ``box.cfg{}``."

msgid ""
"Otherwise this instance will be a replica joining an existing replica set, "
"so:"
msgstr ""
"В противном случае, данный экземпляр будет репликой, которая подключается к "
"существующему набору реплик, поэтому:"

msgid ""
"Bootstrap from the leader. See examples in section :ref:`Bootstrapping a "
"replica set <replication-bootstrap>`."
msgstr ""
"Настройка от лидера. См. примеры в разделе :ref:`Настройка набора реплик "
"<replication-bootstrap>`."

msgid "In background, sync with all the other nodes in the replication set."
msgstr ""
"Синхронизация со всеми остальными узлами в наборе реплик в фоновом режиме."

msgid "**Situation 2: recovery**"
msgstr "**Ситуация 2: восстановление**"

msgid ""
"Here ``box.cfg{}`` is not being called for the first time. It is being "
"called again in order to perform recovery."
msgstr ""
"Здесь вызов ``box.cfg{}`` происходит не впервые, а повторно для "
"осуществления восстановления."

msgid ""
"Perform :ref:`recovery <internals-recovery_process>` from the last local "
"snapshot and the WAL files."
msgstr ""
"Проведение :ref:`восстановления <internals-recovery_process>` из последнего "
"локального снимка и WAL-файлов."

msgid ""
"Connect to at least :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>` nodes. If failed -- set status to 'orphan'. "
"(Attempts to sync will continue in the background and when/if they succeed "
"then 'orphan' will be changed to 'connected'.)"
msgstr ""
"Установить соединение с количеством узлов не меньшим, чем "
":ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`. Если не получается -- установить статус "
"'orphan'. (Попытки синхронизации будут повторяться в фоновом режиме, и "
"когда/если они окажутся успешными, статус 'orphan' сменится на 'connected'.)"

msgid ""
"If connected - sync with all connected nodes, until the difference is not "
"more than :ref:`replication_sync_lag <cfg_replication-replication_sync_lag>`"
" seconds."
msgstr ""
"Если соединение установлено - осуществлять синхронизацию со всеми "
"подключенными узлами до тех пор, пока отличия не будут более "
":ref:`replication_sync_lag <cfg_replication-replication_sync_lag>` секунд."

msgid "**Situation 3: configuration update**"
msgstr "**Ситуация 3: обновление конфигурации**"

msgid ""
"Here ``box.cfg{}`` is not being called for the first time. It is being "
"called again because some replication parameter or something in the replica "
"set has changed."
msgstr ""
"Здесь вызов ``box.cfg{}`` происходит не впервые, а повторно, поскольку "
"изменились некоторые параметры репликации или что-то в наборе реплик."

msgid ""
"Try to connect to all nodes from ``box.cfg.replication``, or to the number "
"of nodes required by :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`, within the time period specified in "
":ref:`replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>`."
msgstr ""
"Попытка установить соединение со всеми узлами из ``box.cfg.replication`` или"
" с количеством узлов, указанным в параметре :ref:`replication_connect_quorum"
" <cfg_replication-replication_connect_quorum>` в течение периода времени, "
"указанного в :ref:`replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>`."

msgid ""
"Try to sync with the connected nodes, within the time period specified in "
":ref:`replication_sync_timeout <cfg_replication-replication_sync_timeout>`."
msgstr ""
"Попытка синхронизации со всеми подключенными узлами в течение периода "
"времени, указанного в :ref:`replication_sync_timeout <cfg_replication-"
"replication_sync_timeout>`."

msgid ""
"If earlier steps fail, change status to 'orphan'. (Attempts to sync will "
"continue in the background and when/if they succeed then 'orphan' status "
"will end.)"
msgstr ""
"Если предыдущие шаги не выполнены, статус изменяется на 'orphan' "
"(одиночный). (Попытки синхронизации будут продолжаться в фоновом режиме, и "
"когда/если они будут успешны, статус 'orphan' отключится.)"

msgid ""
"If earlier steps succeed, set status to 'running' (master) or 'follow' "
"(replica)."
msgstr ""
"Если предыдущие шаги выполнены, статус изменяется на 'running' (мастер) или "
"'follow' (реплика)."

msgid "**Situation 4: rebootstrap**"
msgstr "**Ситуация 4: повторная настройка**"

msgid ""
"Here ``box.cfg{}`` is not being called. The replica connected successfully "
"at some point in the past, and is now ready for an update from the master. "
"But the master cannot provide an update. This can happen by accident, or "
"more likely can happen because the replica is slow (its :ref:`lag "
"<cfg_replication-replication_sync_lag>` is large), and the WAL (.xlog) files"
" containing the updates have been deleted. This is not crippling. The "
"replica can discard what it received earlier, and then ask for the master's "
"latest snapshot (.snap) file contents. Since it is effectively going through"
" the bootstrap process a second time, this is called \"rebootstrapping\". "
"However, there has to be one difference from an ordinary bootstrap -- the "
"replica's :ref:`replica id <replication-replica-id>` will remain the same. "
"If it changed, then the master would think that the replica is a new "
"addition to the cluster, and would maintain a record of an instance ID of a "
"replica that has ceased to exist. Rebootstrapping was introduced in "
"Tarantool version 1.10.2 and is completely automatic."
msgstr ""
"Здесь не происходит вызов ``box.cfg{}``. В определенный момент в прошлом "
"реплика успешно установила соединение и в настоящий момент ожидает "
"обновления от мастера. Однако мастер не может передать обновления, что может"
" произойти случайно, или же если реплика работает слишком медленно (большое "
"значение :ref:`lag <cfg_replication-replication_sync_lag>`), а WAL-файлы "
"(.xlog) с обновлениями были удалены. Такая ситуация не является критической "
"-- реплика может сбросить ранее полученные данные, а затем запросить "
"содержание последнего файла снимка (.snap) мастера. Поскольку фактически в "
"таком случае повторно проводится процесс настройки, это называется "
"\"повторная настройка\". Тем не менее, есть отличие от обычной настройки -- "
":ref:`идентификатор реплики <replication-replica-id>` останется прежним. "
"Если он изменится, то мастер посчитает, что в кластер добавляется новая "
"реплика, и сохранит идентификатор экземпляра реплики, которой уже не "
"существует. Полностью автоматизированный процесс повторной настройки "
"появился в версии Tarantool 1.10.2."

msgid "Server startup with replication"
msgstr "Запуск сервера с репликацией"

msgid ""
"In addition to the recovery process described in the section :ref:`Recovery "
"process <internals-recovery_process>`, the server must take additional steps"
" and precautions if :ref:`replication <replication>` is enabled."
msgstr ""
"Помимо процесса восстановления, описанного в разделе :ref:`Процесс "
"восстановления <internals-recovery_process>`, сервер должен предпринять "
"дополнительные шаги и меры предосторожности, если включена :ref:`репликация "
"<replication>`."

msgid ""
"Once again the startup procedure is initiated by the ``box.cfg{}`` request. "
"One of the ``box.cfg`` parameters may be :ref:`replication <cfg_replication-"
"replication>` which specifies replication source(-s). We will refer to this "
"replica, which is starting up due to ``box.cfg``, as the \"local\" replica "
"to distinguish it from the other replicas in a replica set, which we will "
"refer to as \"distant\" replicas."
msgstr ""
"И снова процедура запуска начинается с запроса ``box.cfg{}``. Одним из "
"параметров запроса ``box.cfg`` может быть :ref:`replication "
"<cfg_replication-replication>`, в котором указываются источники репликации. "
"Реплику, которая запускается сейчас с помощью ``box.cfg``, мы будем называть"
" локальной, чтобы отличать ее от других реплик в наборе реплик, которые мы "
"будем называть удаленными."

msgid ""
"*If there is no snapshot .snap file and the* ``replication`` *parameter is "
"empty and* ``cfg.read_only=false``: |br| then the local replica assumes it "
"is an unreplicated \"standalone\" instance, or is the first replica of a new"
" replica set. It will generate new UUIDs for itself and for the replica set."
" The replica UUID is stored in the ``_cluster`` space; the replica set UUID "
"is stored in the ``_schema`` space. Since a snapshot contains all the data "
"in all the spaces, that means the local replica's snapshot will contain the "
"replica UUID and the replica set UUID. Therefore, when the local replica "
"restarts on later occasions, it will be able to recover these UUIDs when it "
"reads the .snap file."
msgstr ""
"*Если нет файла снимка .snap и не указано значение параметра* "
"``replication`` *и* ``cfg.read_only=false``: |br| то локальная реплика "
"предполагает, что является нереплицируемым обособленным экземпляром или же "
"первой репликой в новом наборе реплик. Она сгенерирует новые UUID для себя и"
" для набора реплик. UUID реплики хранится в спейсе ``_cluster``; UUID набора"
" реплик хранится в спейсе ``_schema``. Поскольку снимок содержит все данные "
"во всех спейсах, это означает, что снимок локальной реплики будет содержать "
"UUID реплики и UUID набора реплик. Таким образом, когда локальная реплика "
"будет позднее перезапускаться, она сможет восстановить эти UUID после "
"прочтения файла снимка .snap."

msgid ""
"*If there is no snapshot .snap file and the* ``replication`` *parameter is "
"empty and* ``cfg.read_only=true``: |br| it cannot be the first replica of a "
"new replica set because the first replica must be a master. Therefore an "
"error message will occur: ER_BOOTSTRAP_READONLY. To avoid this, change the "
"setting for this (local) instance to ``read_only = false``, or ensure that "
"another (distant) instance starts first and has the local instance's UUID in"
" its ``_cluster`` space. In the latter case, if ER_BOOTSTRAP_READONLY still "
"occurs, set the local instance's :ref:`box.replication_connect_timeout "
"<cfg_replication-replication_connect_timeout>` to a larger value."
msgstr ""
"*Если нет файла снимка .snap, не указано значение параметра* ``replication``"
" *и* ``cfg.read_only=true``:|br| такая реплика не может быть первой, потому "
"что первая реплика должна быть мастером. Поэтому выдастся ошибка: "
"ER_BOOTSTRAP_READONLY. Чтобы этого избежать, измените в настройке локального"
" экземпляра ``read_only`` на ``false``, или убедитесь, что удаленный "
"экземпляр запускается первым и имеет UUID локального экземпляра в спейсе "
"``_cluster``. Во втором случае, если произойдет ER_BOOTSTRAP_READONLY, "
"выставите на локальном экземпляре :ref:`box.replication_connect_timeout "
"<cfg_replication-replication_connect_timeout>` на большее значение."

msgid ""
"*If there is no snapshot .snap file and the* ``replication`` *parameter is "
"not empty and the* ``_cluster`` *space contains no other replica UUIDs*: "
"|br| then the local replica assumes it is not a standalone instance, but is "
"not yet part of a replica set. It must now join the replica set. It will "
"send its replica UUID to the first distant replica which is listed in "
"``replication`` and which will act as a master. This is called the \"join "
"request\". When a distant replica receives a join request, it will send "
"back:"
msgstr ""
"*Если нет файла снимка .snap, указано значение параметра* ``replication``, "
"*а в спейсе* ``_cluster`` *отсутствуют UUID других реплик*: |br| то "
"локальная реплика предполагает, что не является обособленным экземпляром, но"
" еще не входит в набор реплик. Сейчас она должна подключиться в набор "
"реплик. Она отправит свой UUID реплики первой удаленной реплике, указанной в"
" параметре ``replication``, которая будет выступать в качестве мастера. Это "
"называется \"запрос на подключение\". Когда удаленная реплика получает "
"запрос на подключение, она отправляет в ответ:"

msgid "the distant replica's replica set UUID,"
msgstr "UUID набора реплик, в который входит удаленная реплика"

msgid ""
"the contents of the distant replica's .snap file. |br| When the local "
"replica receives this information, it puts the replica set UUID in its "
"``_schema`` space, puts the distant replica's UUID and connection "
"information in its ``_cluster`` space, and makes a snapshot containing all "
"the data sent by the distant replica. Then, if the local replica has data in"
" its WAL .xlog files, it sends that data to the distant replica. The distant"
" replica will receive this and update its own copy of the data, and add the "
"local replica's UUID to its ``_cluster`` space."
msgstr ""
"содержимое файла снимка .snap удаленной реплики. |br| Когда локальная "
"реплика получает эту информацию, она размещает UUID набора реплики в своем "
"спейсе ``_schema``, UUID удаленной реплики и информацию о подключении в "
"своем спейсе ``_cluster``, а затем создает снимок, который содержит все "
"данные, отправленные удаленной репликой. Затем, если в WAL-файлах .xlog "
"локальной реплики содержатся данные, они отправляются на удаленную реплику. "
"Удаленная реплика получается данные и обновляет свою копию данных, а затем "
"добавляет UUID локальной реплики в свой спейс ``_cluster``."

msgid ""
"*If there is no snapshot .snap file and the* ``replication`` *parameter is "
"not empty and the* ``_cluster`` *space contains other replica UUIDs*: |br| "
"then the local replica assumes it is not a standalone instance, and is "
"already part of a replica set. It will send its replica UUID and replica set"
" UUID to all the distant replicas which are listed in ``replication``. This "
"is called the \"on-connect handshake\". When a distant replica receives an "
"on-connect handshake: |br|"
msgstr ""
"*Если нет файла снимка .snap, указано значение параметра* ``replication``, "
"*а в спейсе* ``_cluster`` *есть UUID других реплик*: |br| то локальная "
"реплика предполагает, что не является обособленным экземпляром, и уже входит"
" в набор реплик. Она отправит свой UUID реплики и UUID набора реплик всем "
"удаленным репликам, указанным в параметре ``replication``. Это называется "
"\"подтверждение связи при подключении\". Когда удаленная реплика получает "
"подтверждение связи при подключении: |br|"

msgid ""
"the distant replica compares its own copy of the replica set UUID to the one"
" in the on-connect handshake. If there is no match, then the handshake fails"
" and the local replica will display an error."
msgstr ""
"удаленная реплика сопоставляет свою версию UUID набора реплик с UUID, "
"переданным в ходе подтверждения связи при подключении. Если они не "
"совпадают, связь не устанавливается, и локальная реплика отобразит ошибку."

msgid ""
"the distant replica looks for a record of the connecting instance in its "
"``_cluster`` space. If there is none, then the handshake fails. |br| "
"Otherwise the handshake is successful. The distant replica will read any new"
" information from its own .snap and .xlog files, and send the new requests "
"to the local replica."
msgstr ""
"удаленная реплика ищет запись о подключающемся экземпляре в своем спейсе "
"``_cluster``. Если такой записи нет, связь не устанавливается. |br| Если "
"есть, связь подтверждается. Удаленная реплика выполняет чтение любой новой "
"информации из своих файлов .snap и .xlog и отправляет новые запросы на "
"локальную реплику."

msgid ""
"In the end, the local replica knows what replica set it belongs to, the "
"distant replica knows that the local replica is a member of the replica set,"
" and both replicas have the same database contents."
msgstr ""
"Наконец, локальная реплика понимает, к какому набору реплик относится, "
"удаленная реплика понимает, что локальная реплика входит в набор реплик, и у"
" двух реплик одинаковое содержимое базы данных."

msgid ""
"*If there is a snapshot file and replication source is not empty*: |br| "
"first the local replica goes through the recovery process described in the "
"previous section, using its own .snap and .xlog files. Then it sends a "
"\"subscribe\" request to all the other replicas of the replica set. The "
"subscribe request contains the server vector clock. The vector clock has a "
"collection of pairs 'server id, lsn' for every replica in the ``_cluster`` "
"system space. Each distant replica, upon receiving a subscribe request, will"
" read its .xlog files' requests and send them to the local replica if (lsn "
"of .xlog file request) is greater than (lsn of the vector clock in the "
"subscribe request). After all the other replicas of the replica set have "
"responded to the local replica's subscribe request, the replica startup is "
"complete."
msgstr ""
"*Если есть файл снимка и указан источник репликации*: |br| сначала локальная"
" реплика проходит процесс восстановления, описанный в предыдущем разделе, "
"используя свои собственные файлы .snap и .xlog. Затем она отправляет запрос "
"подписки всем репликам в наборе реплик. Запрос подписки содержит векторные "
"часы сервера. Векторные часы включают набор пар 'идентификатор сервера, LSN'"
" для каждой реплики в системном спейсе ``_cluster``. Каждая удаленная "
"реплика, получив запрос подписки, выполняет чтение запросов из файла .xlog и"
" отправляет их на локальную реплику, если LSN из запроса файла .xlog больше,"
" чем LSN векторных часов из запроса подписки. После того, как все реплики из"
" набора реплик отправили ответ на запрос подписки локальной реплики, запуск "
"реплики завершен."

msgid ""
"The following temporary limitations applied for Tarantool versions earlier "
"than 1.7.7:"
msgstr ""
"Следующие временные ограничения применимы к версиям Tarantool ниже 1.7.7:"

msgid ""
"The URIs in the ``replication`` parameter should all be in the same order on"
" all replicas. This is not mandatory but is an aid to consistency."
msgstr ""
"URI в параметре ``replication`` должны быть указаны в одинаковом порядке на "
"всех репликах. Это необязательно, но помогает соблюдать консистентность."

msgid ""
"The replicas of a replica set should be started up at slightly different "
"times. This is not mandatory but prevents a situation where each replica is "
"waiting for the other replica to be ready."
msgstr ""
"Реплики в наборе реплик должны запускаться не одновременно. Это "
"необязательно, но помогает избежать ситуации, когда все реплики ждут "
"готовности друг друга."

msgid ""
"The following limitation still applies for the current Tarantool version:"
msgstr "Следующее ограничение всё еще применимо к текущей версии Tarantool:"

msgid ""
"The maximum number of entries in the ``_cluster`` space is :ref:`32 "
"<limitations_replicas>`. Tuples for out-of-date replicas are not "
"automatically re-used, so if this 32-replica limit is reached, users may "
"have to reorganize the ``_cluster`` space manually."
msgstr ""
"Максимальное количество записей в спейсе ``_cluster`` -- :ref:`32 "
"<limitations_replicas>`. Кортежи для устаревших реплик не переиспользуются "
"автоматически, поэтому по достижении предела в 32 реплики, может "
"понадобиться реорганизация спейса ``_cluster`` вручную."
