# SOME DESCRIPTIVE TITLE.
# Copyright (C)
# This file is distributed under the same license as the Tarantool package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
msgid ""
msgstr ""
"Project-Id-Version: Tarantool 1.10\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-02-06 14:05+0000\n"
"PO-Revision-Date: 2019-12-06 16:11+0300\n"
"Last-Translator: \n"
"Language: ru\n"
"Language-Team: \n"
"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && "
"n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

msgid "Adding instances"
msgstr "Добавление экземпляров"

msgid "Adding a replica"
msgstr "Добавление реплики"

msgid ""
"To add a second **replica** instance to the **master-replica** set from "
"our :ref:`bootstrapping example <replication-master_replica_bootstrap>`, "
"we need an analog of the instance file that we created for the first "
"replica in that set:"
msgstr ""
"Чтобы добавить вторую **реплику** в набор реплик с конфигурацией "
"**мастер-реплика** из нашего :ref:`примера настройки <replication-"
"master_replica_bootstrap>`, необходим аналог файла экземпляра, который мы"
" создали для первой реплики в этом наборе:"

msgid ""
"-- instance file for replica #2\n"
"box.cfg{\n"
"  listen = 3301,\n"
"  replication = {'replicator:password@192.168.0.101:3301',  -- master URI"
"\n"
"                 'replicator:password@192.168.0.102:3301',  -- replica #1"
" URI\n"
"                 'replicator:password@192.168.0.103:3301'}, -- replica #2"
" URI\n"
"  read_only = true\n"
"}\n"
"box.once(\"schema\", function()\n"
"   box.schema.user.create('replicator', {password = 'password'})\n"
"   box.schema.user.grant('replicator', 'replication') -- grant "
"replication role\n"
"   box.schema.space.create(\"test\")\n"
"   box.space.test:create_index(\"primary\")\n"
"   print('box.once executed on replica #2')\n"
"end)"
msgstr ""
"-- файл экземпляра для реплики №2\n"
"box.cfg{\n"
"  listen = 3301,\n"
"  replication = {'replicator:password@192.168.0.101:3301',  -- URI "
"мастера\n"
"                 'replicator:password@192.168.0.102:3301',  -- URI "
"реплики №1\n"
"                 'replicator:password@192.168.0.103:3301'}, -- URI "
"реплики №2\n"
"  read_only = true\n"
"}\n"
"box.once(\"schema\", function()\n"
"   box.schema.user.create('replicator', {password = 'password'})\n"
"   box.schema.user.grant('replicator', 'replication') -- предоставить "
"роль для репликации\n"
"   box.schema.space.create(\"test\")\n"
"   box.space.test:create_index(\"primary\")\n"
"   print('box.once executed on replica #2')\n"
"end)"

msgid ""
"Here we add the URI of replica #2 to the :ref:`replication "
"<cfg_replication-replication>` parameter, so now it contains three URIs."
msgstr ""
"Здесь мы добавляем URI реплики №2 в параметр :ref:`replication "
"<cfg_replication-replication>`, так что теперь он содержит три URI."

msgid ""
"After we launch the new replica instance, it gets connected to the master"
" instance and retrieves the master's write-ahead-log and snapshot files:"
msgstr ""
"После запуска новая реплика подключается к мастер-серверу и получает от "
"него журнал упреждающей записи и файлы снимков:"

msgid ""
"$ # launching replica #2\n"
"$ tarantool replica2.lua\n"
"2017-06-14 14:54:33.927 [46945] main/101/replica2.lua C> version "
"1.7.4-52-g980d30092\n"
"2017-06-14 14:54:33.927 [46945] main/101/replica2.lua C> log level 5\n"
"2017-06-14 14:54:33.928 [46945] main/101/replica2.lua I> mapping "
"268435456 bytes for tuple arena...\n"
"2017-06-14 14:54:33.930 [46945] main/104/applier/replicator@192.168.0.10 "
"I> remote master is 1.7.4 at 192.168.0.101:3301\n"
"2017-06-14 14:54:33.930 [46945] main/104/applier/replicator@192.168.0.10 "
"I> authenticated\n"
"2017-06-14 14:54:33.930 [46945] main/101/replica2.lua I> bootstrapping "
"replica from 192.168.0.101:3301\n"
"2017-06-14 14:54:33.933 [46945] main/104/applier/replicator@192.168.0.10 "
"I> initial data received\n"
"2017-06-14 14:54:33.933 [46945] main/104/applier/replicator@192.168.0.10 "
"I> final data received\n"
"2017-06-14 14:54:33.934 [46945] snapshot/101/main I> saving snapshot "
"`/var/lib/tarantool/replica2/00000000000000000010.snap.inprogress'\n"
"2017-06-14 14:54:33.934 [46945] snapshot/101/main I> done\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> vinyl checkpoint"
" done\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> ready to accept "
"requests\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> set 'read_only' "
"configuration option to true\n"
"2017-06-14 14:54:33.936 [46945] main C> entering the event loop"
msgstr ""
"$ # запуск реплики №2\n"
"$ tarantool replica2.lua\n"
"2017-06-14 14:54:33.927 [46945] main/101/replica2.lua C> version "
"1.7.4-52-g980d30092\n"
"2017-06-14 14:54:33.927 [46945] main/101/replica2.lua C> log level 5\n"
"2017-06-14 14:54:33.928 [46945] main/101/replica2.lua I> mapping "
"268435456 bytes for tuple arena...\n"
"2017-06-14 14:54:33.930 [46945] main/104/applier/replicator@192.168.0.10 "
"I> remote master is 1.7.4 at 192.168.0.101:3301\n"
"2017-06-14 14:54:33.930 [46945] main/104/applier/replicator@192.168.0.10 "
"I> authenticated\n"
"2017-06-14 14:54:33.930 [46945] main/101/replica2.lua I> bootstrapping "
"replica from 192.168.0.101:3301\n"
"2017-06-14 14:54:33.933 [46945] main/104/applier/replicator@192.168.0.10 "
"I> initial data received\n"
"2017-06-14 14:54:33.933 [46945] main/104/applier/replicator@192.168.0.10 "
"I> final data received\n"
"2017-06-14 14:54:33.934 [46945] snapshot/101/main I> saving snapshot "
"`/var/lib/tarantool/replica2/00000000000000000010.snap.inprogress'\n"
"2017-06-14 14:54:33.934 [46945] snapshot/101/main I> done\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> vinyl checkpoint"
" done\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> ready to accept "
"requests\n"
"2017-06-14 14:54:33.935 [46945] main/101/replica2.lua I> set 'read_only' "
"configuration option to true\n"
"2017-06-14 14:54:33.936 [46945] main C> entering the event loop"

msgid ""
"Since we are adding a read-only instance, there is no need to dynamically"
" update the ``replication`` parameter on the other running instances. "
"This update would be required if we :ref:`added a master instance "
"<replication-add_master>`."
msgstr ""
"Поскольку мы добавляем экземпляр только для чтения (read-only), нет "
"необходимости в динамическом обновлении параметра ``replication`` на "
"других работающих экземплярах. Такое обновление необходимо, если бы мы "
":ref:`добавляли мастера <replication-add_master>`."

msgid ""
"However, we recommend specifying the URI of replica #3 in all instance "
"files of the replica set. This will keep all the files consistent with "
"each other and with the current replication topology, and so will help to"
" avoid configuration errors in case of further configuration updates and "
"replica set restart."
msgstr ""
"Тем не менее, рекомендуем указать URI реплики №3 во всех файлах "
"экземпляра в наборе реплик. Это поможет сохранить единообразие файлов и "
"согласовать их с текущей топологией репликации, а также не допустить "
"ошибок конфигурации в случае последующего обновления конфигурации и "
"перезапуска набора реплик."

msgid "Adding a master"
msgstr "Добавление мастера"

msgid ""
"To add a third master instance to the **master-master** set from our "
":ref:`bootstrapping example <replication-master_master_bootstrap>`, we "
"need an analog of the instance files that we created to bootstrap the "
"other master instances in that set:"
msgstr ""
"Чтобы добавить третьего мастера в набор реплик с конфигурацией "
"**мастер-мастер** из нашего :ref:`примера настройки <replication-"
"master_master_bootstrap>`, необходим аналог файлов экземпляров, которые "
"мы создали для настройки других мастеров в этом наборе:"

msgid ""
"-- instance file for master #3\n"
"box.cfg{\n"
"  listen      = 3301,\n"
"  replication = {'replicator:password@192.168.0.101:3301',  -- master#1 "
"URI\n"
"                 'replicator:password@192.168.0.102:3301',  -- master#2 "
"URI\n"
"                 'replicator:password@192.168.0.103:3301'}, -- master#3 "
"URI\n"
"  read_only   = true, -- temporarily read-only\n"
"}\n"
"box.once(\"schema\", function()\n"
"   box.schema.user.create('replicator', {password = 'password'})\n"
"   box.schema.user.grant('replicator', 'replication') -- grant "
"replication role\n"
"   box.schema.space.create(\"test\")\n"
"   box.space.test:create_index(\"primary\")\n"
"end)"
msgstr ""
"-- файл экземпляра для мастера №3\n"
"box.cfg{\n"
"  listen      = 3301,\n"
"  replication = {'replicator:password@192.168.0.101:3301',  -- URI "
"мастера №1\n"
"                 'replicator:password@192.168.0.102:3301',  -- URI "
"мастера №2\n"
"                 'replicator:password@192.168.0.103:3301'}, -- URI "
"мастера №3\n"
"  read_only   = true, -- временно только для чтения\n"
"}\n"
"box.once(\"schema\", function()\n"
"   box.schema.user.create('replicator', {password = 'password'})\n"
"   box.schema.user.grant('replicator', 'replication') -- выдача роли для "
"репликации\n"
"   box.schema.space.create(\"test\")\n"
"   box.space.test:create_index(\"primary\")\n"
"end)"

msgid "Here we make the following changes:"
msgstr "Здесь мы вносим следующие изменения:"

msgid ""
"Add the URI of master #3 to the :ref:`replication <cfg_replication-"
"replication>` parameter."
msgstr ""
"Добавить URI мастера №3 в параметр :ref:`replication <cfg_replication-"
"replication>`."

msgid ""
"Temporarily specify :ref:`read_only=true <cfg_basic-read_only>` to "
"disable data-change operations on the instance. After launch, master #3 "
"will act as a replica until it retrieves all data from the other masters "
"in the replica set."
msgstr ""
"Временно укажите :ref:`read_only=true <cfg_basic-read_only>`, чтобы "
"отключить операции по изменению данных на этом экземпляре. После запуска "
"мастер №3 будет работать в качестве реплики, пока не получит все данные "
"от других мастеров в наборе реплик."

msgid ""
"After we launch master #3, it gets connected to the other master "
"instances and retrieves their write-ahead-log and snapshot files:"
msgstr ""
"После запуска мастер №3 подключается к другим мастер-экземплярам и "
"получает от них файлы журнала упреждающей записи и файлы снимков:"

msgid ""
"$ # launching master #3\n"
"$ tarantool master3.lua\n"
"2017-06-14 17:10:00.556 [47121] main/101/master3.lua C> version "
"1.7.4-52-g980d30092\n"
"2017-06-14 17:10:00.557 [47121] main/101/master3.lua C> log level 5\n"
"2017-06-14 17:10:00.557 [47121] main/101/master3.lua I> mapping 268435456"
" bytes for tuple arena...\n"
"2017-06-14 17:10:00.559 [47121] iproto/101/main I> binary: bound to "
"[::]:3301\n"
"2017-06-14 17:10:00.559 [47121] main/104/applier/replicator@192.168.0.10 "
"I> remote master is 1.7.4 at 192.168.0.101:3301\n"
"2017-06-14 17:10:00.559 [47121] main/105/applier/replicator@192.168.0.10 "
"I> remote master is 1.7.4 at 192.168.0.102:3301\n"
"2017-06-14 17:10:00.559 [47121] main/106/applier/replicator@192.168.0.10 "
"I> remote master is 1.7.4 at 192.168.0.103:3301\n"
"2017-06-14 17:10:00.559 [47121] main/105/applier/replicator@192.168.0.10 "
"I> authenticated\n"
"2017-06-14 17:10:00.559 [47121] main/101/master3.lua I> bootstrapping "
"replica from 192.168.0.102:3301\n"
"2017-06-14 17:10:00.562 [47121] main/105/applier/replicator@192.168.0.10 "
"I> initial data received\n"
"2017-06-14 17:10:00.562 [47121] main/105/applier/replicator@192.168.0.10 "
"I> final data received\n"
"2017-06-14 17:10:00.562 [47121] snapshot/101/main I> saving snapshot "
"`/Users/e.shebunyaeva/work/tarantool-test-"
"repl/master3_dir/00000000000000000009.snap.inprogress'\n"
"2017-06-14 17:10:00.562 [47121] snapshot/101/main I> done\n"
"2017-06-14 17:10:00.564 [47121] main/101/master3.lua I> vinyl checkpoint "
"done\n"
"2017-06-14 17:10:00.564 [47121] main/101/master3.lua I> ready to accept "
"requests\n"
"2017-06-14 17:10:00.565 [47121] main/101/master3.lua I> set 'read_only' "
"configuration option to true\n"
"2017-06-14 17:10:00.565 [47121] main C> entering the event loop\n"
"2017-06-14 17:10:00.565 [47121] main/104/applier/replicator@192.168.0.10 "
"I> authenticated"
msgstr ""
"$ # запуск мастера №3\n"
"$ tarantool master3.lua\n"
"2017-06-14 17:10:00.556 [47121] main/101/master3.lua C> version "
"1.7.4-52-g980d30092\n"
"2017-06-14 17:10:00.557 [47121] main/101/master3.lua C> log level 5\n"
"2017-06-14 17:10:00.557 [47121] main/101/master3.lua I> mapping 268435456"
" bytes for tuple arena...\n"
"2017-06-14 17:10:00.559 [47121] iproto/101/main I> binary: bound to "
"[::]:3301\n"
"2017-06-14 17:10:00.559 [47121] main/104/applier/replicator@192.168.0.10 "
"I> remote master is 1.7.4 at 192.168.0.101:3301\n"
"2017-06-14 17:10:00.559 [47121] main/105/applier/replicator@192.168.0.10 "
"I> remote master is 1.7.4 at 192.168.0.102:3301\n"
"2017-06-14 17:10:00.559 [47121] main/106/applier/replicator@192.168.0.10 "
"I> remote master is 1.7.4 at 192.168.0.103:3301\n"
"2017-06-14 17:10:00.559 [47121] main/105/applier/replicator@192.168.0.10 "
"I> authenticated\n"
"2017-06-14 17:10:00.559 [47121] main/101/master3.lua I> bootstrapping "
"replica from 192.168.0.102:3301\n"
"2017-06-14 17:10:00.562 [47121] main/105/applier/replicator@192.168.0.10 "
"I> initial data received\n"
"2017-06-14 17:10:00.562 [47121] main/105/applier/replicator@192.168.0.10 "
"I> final data received\n"
"2017-06-14 17:10:00.562 [47121] snapshot/101/main I> saving snapshot "
"`/Users/e.shebunyaeva/work/tarantool-test-"
"repl/master3_dir/00000000000000000009.snap.inprogress'\n"
"2017-06-14 17:10:00.562 [47121] snapshot/101/main I> done\n"
"2017-06-14 17:10:00.564 [47121] main/101/master3.lua I> vinyl checkpoint "
"done\n"
"2017-06-14 17:10:00.564 [47121] main/101/master3.lua I> ready to accept "
"requests\n"
"2017-06-14 17:10:00.565 [47121] main/101/master3.lua I> set 'read_only' "
"configuration option to true\n"
"2017-06-14 17:10:00.565 [47121] main C> entering the event loop\n"
"2017-06-14 17:10:00.565 [47121] main/104/applier/replicator@192.168.0.10 "
"I> authenticated"

msgid ""
"Next, we add the URI of master #3 to the ``replication`` parameter on the"
" existing two masters. Replication-related parameters are dynamic, so we "
"only need to make a ``box.cfg{}`` request on each of the running "
"instances:"
msgstr ""
"Затем добавляем URI мастера №3 в параметр ``replication`` на существующих"
" мастерах. В конфигурации репликации используются динамические параметры,"
" поэтому необходимо только выполнить запрос ``box.cfg{}`` на каждом "
"работающем экземпляре:"

msgid ""
"# adding master #3 URI to replication sources\n"
"tarantool> box.cfg{replication =\n"
"         > {'replicator:password@192.168.0.101:3301',\n"
"         > 'replicator:password@192.168.0.102:3301',\n"
"         > 'replicator:password@192.168.0.103:3301'}}\n"
"---\n"
"..."
msgstr ""
"# добавление URI мастера №3 в источники репликации\n"
"tarantool> box.cfg{replication =\n"
"         > {'replicator:password@192.168.0.101:3301',\n"
"         > 'replicator:password@192.168.0.102:3301',\n"
"         > 'replicator:password@192.168.0.103:3301'}}\n"
"---\n"
"..."

msgid ""
"When master #3 catches up with the other masters' state, we can disable "
"read-only mode for this instance:"
msgstr ""
"Когда мастер №3 получает все необходимые изменения от других мастеров, "
"можно отключить режим только для чтения:"

msgid ""
"# making master #3 a real master\n"
"tarantool> box.cfg{read_only=false}\n"
"---\n"
"..."
msgstr ""
"# назначение мастера №3 настоящим мастером\n"
"tarantool> box.cfg{read_only=false}\n"
"---\n"
"..."

msgid ""
"We also recommend to specify master #3 URI in all instance files in order"
" to keep all the files consistent with each other and with the current "
"replication topology."
msgstr ""
"Также рекомендуется указать URI мастера №3 во всех файлах экземпляра, "
"чтобы сохранить единообразие файлов и согласовать их с текущей топологией"
" репликации."

msgid "Orphan status"
msgstr "Статус orphan (одиночный)"

msgid ""
"Starting with Tarantool version 1.9, there is a change to the procedure "
"when an instance joins a replica set. During ``box.cfg()`` the instance "
"will try to join all masters listed in :ref:`box.cfg.replication "
"<cfg_replication-replication>`. If the instance does not succeed with at "
"least the number of masters specified in :ref:`replication_connect_quorum"
" <cfg_replication-replication_connect_quorum>`, then it will switch to "
"**orphan status**. While an instance is in orphan status, it is read-"
"only."
msgstr ""
"Начиная с версии Tarantool'а 1.9, процедура подключения реплики к набору "
"реплик изменяется. Во время ``box.cfg()`` экземпляр попытается "
"подключиться ко всем мастерам, указанным в :ref:`box.cfg.replication "
"<cfg_replication-replication>`. Если не было успешно выполнено "
"подключение к количеству мастеров, указанному в "
":ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`, экземпляр переходит в **статус orphan** "
"(одиночный). Когда экземпляр находится в статусе orphan, он доступен "
"только для чтения."

msgid ""
"To \"join\" a master, a replica instance must \"connect\" to the master "
"node and then \"sync\"."
msgstr ""
"Чтобы \"подключиться\" к мастеру, реплика должна \"установить "
"соединение\" с узлом мастера, а затем \"выполнить синхронизацию\"."

msgid ""
"\"Connect\" means contact the master over the physical network and "
"receive acknowledgment. If there is no acknowledgment after "
":ref:`box.replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>` seconds (usually 4 seconds), and retries "
"fail, then the connect step fails."
msgstr ""
"\"Установка соединения\" означает контакт с мастером по физической сети и"
" получение подтверждения. Если нет подтверждения соединения через "
":ref:`box.replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>` секунд (обычно 4 секунды), и повторные "
"попытки подключения не сработали, то соединение не установлено."

msgid ""
"\"Sync\" means receive updates from the master in order to make a local "
"database copy. Syncing is complete when the replica has received all the "
"updates, or at least has received enough updates that the replica's lag "
"(see :ref:`replication.upstream.lag <box_info_replication_upstream_lag>` "
"in ``box.info()``) is less than or equal to the number of seconds "
"specified in :ref:`box.cfg.replication_sync_lag <cfg_replication-"
"replication_sync_lag>`. If ``replication_sync_lag`` is unset (nil) or set"
" to TIMEOUT_INFINITY, then the replica skips the \"sync\" state and "
"switches to \"follow\" immediately."
msgstr ""
"\"Синхронизация\" означает получение обновлений от мастера для создания "
"локальной копии базы данных. Синхронизация завершена, когда реплика "
"получила все обновления или хотя бы получила достаточное количество "
"обновлений, чтобы отставание реплики (см. :ref:`replication.upstream.lag "
"<box_info_replication_upstream_lag>` в ``box.info()``) было меньше или "
"равно количеству секунд, указанному в :ref:`box.cfg.replication_sync_lag "
"<cfg_replication-replication_sync_lag>`. Если значение "
"``replication_sync_lag`` не задано (nil) или указано как "
"\"TIMEOUT_INFINITY\", то реплика пропускает шаг \"синхронизация\" и сразу"
" же переходит на \"отслеживание\"."

msgid ""
"In order to leave orphan mode you need to sync with a sufficient number "
"(:ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`) of instances. To do so, you may either:"
msgstr ""
"Чтобы вывести узел из одиночного статуса, нужно синхронизировать его с "
"достаточным (т.е. равным :ref:`replication_connect_quorum "
"<cfg_replication-replication_connect_quorum>`) количеством других узлов. "
"Этого можно добиться, выполнив любое из следующих действий:"

msgid ""
"Set :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>` to a lower value."
msgstr ""
"Уменьшить значение :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`."

msgid ""
"Reset ``box.cfg.replication`` to exclude instances that cannot be reached"
" or synced with."
msgstr ""
"Убрать из списка ``box.cfg.replication`` недоступные и прочие узлы, с "
"которыми нельзя синхронизироваться."

msgid "Set ``box.cfg.replication`` to ``\"\"`` (empty string)."
msgstr ""
"Вообще задать ``\"\"`` (пустую строку) в качестве "
"значения``box.cfg.replication``."

msgid "The following situations are possible."
msgstr "Возможны следующие ситуации."

msgid "**Situation 1: bootstrap**"
msgstr "**Ситуация 1: настройка**"

msgid ""
"Here ``box.cfg{}`` is being called for the first time. A replica is "
"joining but no replica set exists yet."
msgstr ""
"Здесь впервые происходит вызов ``box.cfg{}``. Реплика подключается, но "
"набора реплик пока нет."

msgid "Set status to 'orphan'."
msgstr "Установка статуса 'orphan' (одиночный)."

msgid ""
"Try to connect to all nodes from ``box.cfg.replication``, or to the "
"number of nodes required by :ref:`replication_connect_quorum "
"<cfg_replication-replication_connect_quorum>`. Retrying up to 3 times in "
"30 seconds is possible because this is bootstrap, "
":ref:`replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>` is overridden."
msgstr ""
"Попытка установить соединение со всеми узлами из ``box.cfg.replication`` "
"или с количеством узлов, указанным в параметре "
":ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`. Допускаются три повторные попытки за 30 "
"секунд, поскольку идет стадия настройки, параметр "
":ref:`replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>` не учитывается."

msgid ""
"Abort and throw an error if not connected to all nodes in "
"``box.cfg.replication`` or :ref:`replication_connect_quorum "
"<cfg_replication-replication_connect_quorum>`."
msgstr ""
"Прекращение работы и выдача ошибки в случае отсутствия соединения со "
"всеми узлами в ``box.cfg.replication`` или "
":ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`."

msgid ""
"This instance might be elected as the replica set 'leader'. Criteria for "
"electing a leader include vclock value (largest is best), and whether it "
"is read-only or read-write (read-write is best unless there is no other "
"choice). The leader is the master that other instances must join. The "
"leader is the master that executes :ref:`box_once() <box-once>` "
"functions."
msgstr ""
"Экземпляр может быть выбран в качестве лидера 'leader' в наборе реплик. "
"Критерии выбора лидера включают в себя значение vclock (чем больше, тем "
"лучше), а также доступность только для чтения или для чтения и записи "
"(лучше всего для чтения и записи, кроме случаев, когда других вариантов "
"нет). Лидер является мастером, к которому должны подключиться другие "
"экземпляры. Лидер является мастером, который выполняет функции "
":ref:`box_once() <box-once>`."

msgid ""
"If this instance is elected as the replica set leader, then perform an "
"\"automatic bootstrap\":"
msgstr ""
"Если данный экземпляр выбран лидером набора реплик, выполняется "
"\"самонастройка\":"

msgid "Set status to 'running'."
msgstr "Установка статуса 'running' (запущен)."

msgid "Return from ``box.cfg{}``."
msgstr "Возврат из ``box.cfg{}``."

msgid ""
"Otherwise this instance will be a replica joining an existing replica "
"set, so:"
msgstr ""
"В противном случае, данный экземпляр будет репликой, которая подключается"
" к существующему набору реплик, поэтому:"

msgid ""
"Bootstrap from the leader. See examples in section :ref:`Bootstrapping a "
"replica set <replication-bootstrap>`."
msgstr ""
"Настройка от лидера. См. примеры в разделе :ref:`Настройка набора реплик "
"<replication-bootstrap>`."

msgid "In background, sync with all the other nodes in the replication set."
msgstr "Синхронизация со всеми остальными узлами в наборе реплик в фоновом режиме."

msgid "**Situation 2: recovery**"
msgstr "**Ситуация 2: восстановление**"

msgid ""
"Here ``box.cfg{}`` is not being called for the first time. It is being "
"called again in order to perform recovery."
msgstr ""
"Здесь вызов ``box.cfg{}`` происходит не впервые, а повторно для "
"осуществления восстановления."

msgid ""
"Perform :ref:`recovery <internals-recovery_process>` from the last local "
"snapshot and the WAL files."
msgstr ""
"Проведение :ref:`восстановления <internals-recovery_process>` из "
"последнего локального снимка и WAL-файлов."

msgid ""
"Connect to at least :ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>` nodes. If failed - set status to 'orphan'. "
"(Attempts to sync will continue in the background and when/if they "
"succeed then 'orphan' will be changed to 'connected'.)"
msgstr ""
"Установить соединение с количеством узлов не меньшим, чем "
":ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>`. Если не получается - установить статус "
"'orphan'. (Попытки синхронизации будут повторяться в фоновом режиме, и "
"когда/если они окажутся успешными, статус 'orphan' сменится на "
"'connected'.)"

msgid ""
"If connected - sync with all connected nodes, until the difference is not"
" more than :ref:`replication_sync_lag <cfg_replication-"
"replication_sync_lag>` seconds."
msgstr ""
"Если соединение установлено - осуществлять синхронизацию со всеми "
"подключенными узлами до тех пор, пока отличия не будут более "
":ref:`replication_sync_lag <cfg_replication-replication_sync_lag>` "
"секунд."

msgid "**Situation 3: configuration update**"
msgstr "**Ситуация 3: обновление конфигурации**"

msgid ""
"Here ``box.cfg{}`` is not being called for the first time. It is being "
"called again because some replication parameter or something in the "
"replica set has changed."
msgstr ""
"Здесь вызов ``box.cfg{}`` происходит не впервые, а повторно, поскольку "
"изменились некоторые параметры репликации или что-то в наборе реплик."

msgid ""
"Try to connect to all nodes from ``box.cfg.replication``, or to the "
"number of nodes required by :ref:`replication_connect_quorum "
"<cfg_replication-replication_connect_quorum>`, within the time period "
"specified in :ref:`replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>`."
msgstr ""
"Попытка установить соединение со всеми узлами из ``box.cfg.replication`` "
"или с количеством узлов, указанным в параметре "
":ref:`replication_connect_quorum <cfg_replication-"
"replication_connect_quorum>` в течение периода времени, указанного в "
":ref:`replication_connect_timeout <cfg_replication-"
"replication_connect_timeout>`."

msgid ""
"Try to sync with the connected nodes, within the time period specified in"
" :ref:`replication_sync_timeout <cfg_replication-"
"replication_sync_timeout>`."
msgstr ""
"Попытка синхронизации со всеми подключенными узлами в течение периода "
"времени, указанного в :ref:`replication_sync_timeout <cfg_replication-"
"replication_sync_timeout>`."

msgid ""
"If earlier steps fail, change status to 'orphan'. (Attempts to sync will "
"continue in the background and when/if they succeed then 'orphan' status "
"will end.)"
msgstr ""
"Если предыдущие шаги не выполнены, статус изменяется на 'orphan' "
"(одиночный). (Попытки синхронизации будут продолжаться в фоновом режиме, "
"и когда/если они будут успешны, статус 'orphan' отключится.)"

msgid ""
"If earlier steps succeed, set status to 'running' (master) or 'follow' "
"(replica)."
msgstr ""
"Если предыдущие шаги выполнены, статус изменяется на 'running' (мастер) "
"или 'follow' (реплика)."

msgid "**Situation 4: rebootstrap**"
msgstr "**Ситуация 4: повторная настройка**"

msgid ""
"Here ``box.cfg{}`` is not being called. The replica connected "
"successfully at some point in the past, and is now ready for an update "
"from the master. But the master cannot provide an update. This can happen"
" by accident, or more likely can happen because the replica is slow (its "
":ref:`lag <cfg_replication-replication_sync_lag>` is large), and the WAL "
"(.xlog) files containing the updates have been deleted. This is not "
"crippling. The replica can discard what it received earlier, and then ask"
" for the master's latest snapshot (.snap) file contents. Since it is "
"effectively going through the bootstrap process a second time, this is "
"called \"rebootstrapping\". However, there has to be one difference from "
"an ordinary bootstrap -- the replica's :ref:`replica id <replication-"
"replica-id>` will remain the same. If it changed, then the master would "
"think that the replica is a new addition to the cluster, and would "
"maintain a record of an instance ID of a replica that has ceased to "
"exist. Rebootstrapping was introduced in Tarantool version 1.10.2 and is "
"completely automatic."
msgstr ""
"Здесь не происходит вызов ``box.cfg{}``. В определенный момент в прошлом "
"реплика успешно установила соединение и в настоящий момент ожидает "
"обновления от мастера. Однако мастер не может передать обновления, что "
"может произойти случайно, или же если реплика работает слишком медленно "
"(большое значение :ref:`lag <cfg_replication-replication_sync_lag>`), а "
"WAL-файлы (.xlog) с обновлениями были удалены. Такая ситуация не является"
" критической -- реплика может сбросить ранее полученные данные, а затем "
"запросить содержание последнего файла снимка (.snap) мастера. Поскольку "
"фактически в таком случае повторно проводится процесс настройки, это "
"называется \"повторная настройка\". Тем не менее, есть отличие от обычной"
" настройки -- :ref:`идентификатор реплики <replication-replica-id>` "
"останется прежним. Если он изменится, то мастер посчитает, что в кластер "
"добавляется новая реплика, и сохранит идентификатор экземпляра реплики, "
"которой уже не существует. Полностью автоматизированный процесс повторной"
" настройки появился в версии Tarantool'а 1.10.2."

msgid "Server startup with replication"
msgstr "Запуск сервера с репликацией"

msgid ""
"In addition to the recovery process described in the section "
":ref:`Recovery process <internals-recovery_process>`, the server must "
"take additional steps and precautions if :ref:`replication <replication>`"
" is enabled."
msgstr ""
"Помимо процесса восстановления, описанного в разделе :ref:`Процесс "
"восстановления <internals-recovery_process>`, сервер должен предпринять "
"дополнительные шаги и меры предосторожности, если включена "
":ref:`репликация <replication>`."

msgid ""
"Once again the startup procedure is initiated by the ``box.cfg{}`` "
"request. One of the ``box.cfg`` parameters may be :ref:`replication "
"<cfg_replication-replication>` which specifies replication source(-s). We"
" will refer to this replica, which is starting up due to ``box.cfg``, as "
"the \"local\" replica to distinguish it from the other replicas in a "
"replica set, which we will refer to as \"distant\" replicas."
msgstr ""
"И снова процедура запуска начинается с запроса ``box.cfg{}``. Одним из "
"параметров запроса ``box.cfg`` может быть :ref:`replication "
"<cfg_replication-replication>`, в котором указываются источники "
"репликации. Реплику, которая запускается сейчас с помощью ``box.cfg``, мы"
" будем называть локальной, чтобы отличать ее от других реплик в наборе "
"реплик, которые мы будем называть удаленными."

msgid ""
"*If there is no snapshot .snap file and the 'replication' parameter is "
"empty*: |br| then the local replica assumes it is an unreplicated "
"\"standalone\" instance, or is the first replica of a new replica set. It"
" will generate new UUIDs for itself and for the replica set. The replica "
"UUID is stored in the ``_cluster`` space; the replica set UUID is stored "
"in the ``_schema`` space. Since a snapshot contains all the data in all "
"the spaces, that means the local replica's snapshot will contain the "
"replica UUID and the replica set UUID. Therefore, when the local replica "
"restarts on later occasions, it will be able to recover these UUIDs when "
"it reads the .snap file."
msgstr ""
"*Если нет файла снимка .snap и не указано значение параметра "
"`replication`*: |br| то локальная реплика предполагает, что является "
"нереплицируемым обособленным экземпляром или же первой репликой в новом "
"наборе реплик. Она сгенерирует новые UUID для себя и для набора реплик. "
"UUID реплики хранится в спейсе ``_cluster``; UUID набора реплик хранится "
"в спейсе ``_schema``. Поскольку снимок содержит все данные во всех "
"спейсах, это означает, что снимок локальной реплики будет содержать UUID "
"реплики и UUID набора реплик. Таким образом, когда локальная реплика "
"будет позднее перезапускаться, она сможет восстановить эти UUID после "
"прочтения файла снимка .snap."

msgid ""
"*If there is no snapshot .snap file and the 'replication' parameter is "
"not empty and the '_cluster' space contains no other replica UUIDs*: |br|"
" then the local replica assumes it is not a standalone instance, but is "
"not yet part of a replica set. It must now join the replica set. It will "
"send its replica UUID to the first distant replica which is listed in "
"``replication`` and which will act as a master. This is called the \"join"
" request\". When a distant replica receives a join request, it will send "
"back:"
msgstr ""
"*Если нет файла снимка .snap, указано значение параметра `replication`, а"
" в спейсе `_cluster` отсутствуют UUID других реплик*: |br| то локальная "
"реплика предполагает, что не является обособленным экземпляром, но еще не"
" входит в набор реплик. Сейчас она должна быть подключиться в набор "
"реплик. Она отправит свой UUID реплики первой удаленной реплике, "
"указанной в параметре ``replication``, которая будет выступать в качестве"
" мастера. Это называется \"запрос на подключение\". Когда удаленная "
"реплика получает запрос на подключение, она отправляет в ответ:"

msgid "the distant replica's replica set UUID,"
msgstr "UUID набора реплик, в который входит удаленная реплика"

msgid ""
"the contents of the distant replica's .snap file. |br| When the local "
"replica receives this information, it puts the replica set UUID in its "
"``_schema`` space, puts the distant replica's UUID and connection "
"information in its ``_cluster`` space, and makes a snapshot containing "
"all the data sent by the distant replica. Then, if the local replica has "
"data in its WAL .xlog files, it sends that data to the distant replica. "
"The distant replica will receive this and update its own copy of the "
"data, and add the local replica's UUID to its ``_cluster`` space."
msgstr ""
"содержимое файла снимка .snap удаленной реплики. |br| Когда локальная "
"реплика получает эту информацию, она размещает UUID набора реплики в "
"своем спейсе ``_schema``, UUID удаленной реплики и информацию о "
"подключении в своем спейсе ``_cluster``, а затем создает снимок, который "
"содержит все данные, отправленные удаленной репликой. Затем, если в "
"WAL-файлах .xlog локальной реплики содержатся данные, они отправляются на"
" удаленную реплику. Удаленная реплика получается данные и обновляет свою "
"копию данных, а затем добавляет UUID локальной реплики в свой спейс "
"``_cluster``."

msgid ""
"*If there is no snapshot .snap file and the 'replication' parameter is "
"not empty and the ``_cluster`` space contains other replica UUIDs*: |br| "
"then the local replica assumes it is not a standalone instance, and is "
"already part of a replica set. It will send its replica UUID and replica "
"set UUID to all the distant replicas which are listed in ``replication``."
" This is called the \"on-connect handshake\". When a distant replica "
"receives an on-connect handshake: |br|"
msgstr ""
"*Если нет файла снимка .snap, указано значение параметра `replication`, а"
" в спейсе ``_cluster`` есть UUID других реплик*: |br| то локальная "
"реплика предполагает, что не является обособленным экземпляром, и уже "
"входит в набор реплик. Она отправит свой UUID реплики и UUID набора "
"реплик всем удаленным репликам, указанным в параметре ``replication``. "
"Это называется \"подтверждение связи при подключении\". Когда удаленная "
"реплика получает подтверждение связи при подключении: |br|"

msgid ""
"the distant replica compares its own copy of the replica set UUID to the "
"one in the on-connect handshake. If there is no match, then the handshake"
" fails and the local replica will display an error."
msgstr ""
"удаленная реплика сопоставляет свою версию UUID набора реплик с UUID, "
"переданным в ходе подтверждения связи при подключении. Если они не "
"совпадают, связь не устанавливается, и локальная реплика отобразит "
"ошибку."

msgid ""
"the distant replica looks for a record of the connecting instance in its "
"``_cluster`` space. If there is none, then the handshake fails. |br| "
"Otherwise the handshake is successful. The distant replica will read any "
"new information from its own .snap and .xlog files, and send the new "
"requests to the local replica."
msgstr ""
"удаленная реплика ищет запись о подключающемся экземпляре в своем спейсе "
"``_cluster``. Если такой записи нет, связь не устанавливается. |br| Если "
"есть, связь подтверждается. Удаленная реплика выполняет чтение любой "
"новой информации из своих файлов .snap и .xlog и отправляет новые запросы"
" на локальную реплику."

msgid ""
"In the end, the local replica knows what replica set it belongs to, the "
"distant replica knows that the local replica is a member of the replica "
"set, and both replicas have the same database contents."
msgstr ""
"Наконец, локальная реплика понимает, к какому набору реплик относится, "
"удаленная реплика понимает, что локальная реплика входит в набор реплик, "
"и у двух реплик одинаковое содержимое базы данных."

msgid ""
"*If there is a snapshot file and replication source is not empty*: |br| "
"first the local replica goes through the recovery process described in "
"the previous section, using its own .snap and .xlog files. Then it sends "
"a \"subscribe\" request to all the other replicas of the replica set. The"
" subscribe request contains the server vector clock. The vector clock has"
" a collection of pairs 'server id, lsn' for every replica in the "
"``_cluster`` system space. Each distant replica, upon receiving a "
"subscribe request, will read its .xlog files' requests and send them to "
"the local replica if (lsn of .xlog file request) is greater than (lsn of "
"the vector clock in the subscribe request). After all the other replicas "
"of the replica set have responded to the local replica's subscribe "
"request, the replica startup is complete."
msgstr ""
"*Если есть файл снимка и указан источник репликации*: |br| сначала "
"локальная реплика проходит процесс восстановления, описанный в предыдущем"
" разделе, используя свои собственные файлы .snap и .xlog. Затем она "
"отправляет запрос подписки всем репликам в наборе реплик. Запрос подписки"
" содержит векторные часы сервера. Векторные часы включают набор пар "
"'идентификатор сервера, LSN' для каждой реплики в системном спейсе "
"``_cluster``. Каждая удаленная реплика, получив запрос подписки, "
"выполняет чтение запросов из файла .xlog и отправляет их на локальную "
"реплику, если LSN из запроса файла .xlog больше, чем LSN векторных часов "
"из запроса подписки. После того, как все реплики из набора реплик "
"отправили ответ на запрос подписки локальной реплики, запуск реплики "
"завершен."

msgid ""
"The following temporary limitations applied for Tarantool versions "
"earlier than 1.7.7:"
msgstr ""
"Следующие временные ограничения применимы к версиям Tarantool'а ниже "
"1.7.7:"

msgid ""
"The URIs in the ``replication`` parameter should all be in the same order"
" on all replicas. This is not mandatory but is an aid to consistency."
msgstr ""
"URI в параметре ``replication`` должны быть указаны в одинаковом порядке "
"на всех репликах. Это необязательно, но помогает соблюдать "
"консистентность."

msgid ""
"The replicas of a replica set should be started up at slightly different "
"times. This is not mandatory but prevents a situation where each replica "
"is waiting for the other replica to be ready."
msgstr ""
"Реплики в наборе реплик должны запускаться не одновременно. Это "
"необязательно, но помогает избежать ситуации, когда все реплики ждут "
"готовности друг друга."

msgid "The following limitation still applies for the current Tarantool version:"
msgstr "Следующее ограничение всё еще применимо к текущей версии Tarantool'а:"

msgid ""
"The maximum number of entries in the ``_cluster`` space is :ref:`32 "
"<limitations_replicas>`. Tuples for out-of-date replicas are not "
"automatically re-used, so if this 32-replica limit is reached, users may "
"have to reorganize the ``_cluster`` space manually."
msgstr ""
"Максимальное количество записей в спейсе ``_cluster`` -- :ref:`32 "
"<limitations_replicas>`. Кортежи для устаревших реплик не "
"переиспользуются автоматически, поэтому по достижении предела в 32 "
"реплики, может понадобиться реорганизация спейса ``_cluster`` вручную."
